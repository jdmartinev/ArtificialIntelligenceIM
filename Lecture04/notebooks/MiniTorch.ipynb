{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJYVo2mdh+buNDSRvg3jgF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdmartinev/ArtificialIntelligenceIM/blob/main/Lecture04/notebooks/MiniTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "09Qu96B35Wdu"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "# pick the seed for reproducibility - change it to explore the effects of random variations\n",
        "np.random.seed(0)\n",
        "import random\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "TlUCB_zK6Scx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "# Download and load the test data\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIBpYf996Zit",
        "outputId": "a3e8b679-dd5c-496e-cac1-835a4c55a9f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 11454604.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 348060.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 3106976.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4013172.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Iterate over a few batches\n",
        "for images, labels in trainloader:\n",
        "    print(images.shape, labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t4LZI997v-6",
        "outputId": "c01860d9-3bef-469f-dae0-1301c00615c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check some examples\n",
        "for images, labels in trainloader:\n",
        "    # Denormalize the images for plotting\n",
        "    images = images * 0.5 + 0.5\n",
        "\n",
        "    # Plot the images\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(9):  # Plot 9 images\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i][0], cmap='gray')  # images[i][0] for grayscale images\n",
        "        plt.title(f\"Label: {labels[i].item()}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    break\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "UqqrP50f75ns",
        "outputId": "2f115c26-1840-4996-da1d-f132c9a7227f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Layer Exercise**\n",
        "\n",
        "In this exercise, you will implement a simple linear layer, commonly used in neural networks. The linear layer performs a linear transformation on the input data. You will be required to implement the forward pass, backward pass, and update equations for this layer.\n",
        "\n",
        "## **Tasks**\n",
        "\n",
        "You need to implement the following methods in the `Linear` class: `forward`, `backward`, and `update`.\n",
        "\n",
        "### **Forward Pass**\n",
        "\n",
        "In the forward pass, the linear layer computes the output as:\n",
        "\n",
        "$$\\mathbf{Z} = \\mathbf{X} \\mathbf{W} + \\mathbf{b}$$\n",
        "\n",
        "where:\n",
        "- $\\mathbf{X}$ is the input tensor of shape $(n_{\\text{batch}}, n_{\\text{in}})$\n",
        "- $\\mathbf{W}$ is the weight matrix of shape $(n_{\\text{in}}, n_{\\text{out}})$\n",
        "- $\\mathbf{b}$ is the bias vector of shape $(n_{\\text{out}},)$\n",
        "- $\\mathbf{Z}$ is the output tensor of shape $(n_{\\text{batch}}, n_{\\text{out}})$\n",
        "\n",
        "*Tip*: Move to self all the tensors needed to compute the gradient\n",
        "### **Backward Pass**\n",
        "\n",
        "In the backward pass, the gradients of the weights and biases are computed using the chain rule. Given the gradient of the loss with respect to the output $\\mathbf{dZ}$, we compute:\n",
        "\n",
        "$$\\mathbf{dW} = \\mathbf{X}^T \\mathbf{dZ}$$\n",
        "$$\\mathbf{db} = \\sum_{i=1}^{n_{\\text{batch}}} \\mathbf{dZ}_i$$\n",
        "$$\\mathbf{dX} = \\mathbf{dZ} \\mathbf{W}^T$$\n",
        "\n",
        "where:\n",
        "- $\\mathbf{dZ}$ is the gradient of the loss with respect to the output, with shape $(n_{\\text{batch}}, n_{\\text{out}})$\n",
        "- $\\mathbf{dW}$ is the gradient of the loss with respect to the weights, with shape $(n_{\\text{in}}, n_{\\text{out}})$\n",
        "- $\\mathbf{db}$ is the gradient of the loss with respect to the biases, with shape $(n_{\\text{out}},)$\n",
        "- $\\mathbf{dX}$ is the gradient of the loss with respect to the input, with shape $(n_{\\text{batch}}, n_{\\text{in}})$\n",
        "\n",
        "### **Update**\n",
        "\n",
        "In the update step, we adjust the weights and biases using the gradients computed during the backward pass and a learning rate \\(\\alpha\\):\n",
        "\n",
        "$$\\mathbf{W} \\leftarrow \\mathbf{W} - \\alpha \\mathbf{dW}$$\n",
        "$$\\mathbf{b} \\leftarrow \\mathbf{b} - \\alpha \\mathbf{db}$$\n",
        "\n",
        "where:\n",
        "- $\\alpha$ is the learning rate\n",
        "\n",
        "## **Instructions**\n",
        "\n",
        "1. **Forward Method**: Implement the forward pass by computing the linear transformation.\n",
        "2. **Backward Method**: Implement the backward pass by computing the gradients of the weights, biases, and inputs.\n",
        "3. **Update Method**: Implement the update step to adjust the weights and biases using the computed gradients and a given learning rate.\n",
        "\n",
        "Make sure to test your implementation with various input sizes to ensure it works correctly.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jubg93HMPesy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "    \"\"\"\n",
        "    A simple linear layer that performs a linear transformation.\n",
        "    \"\"\"\n",
        "    def __init__(self, nin, nout, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        Initialize the linear layer with random weights and zero biases.\n",
        "\n",
        "        Args:\n",
        "            nin (int): Number of input features.\n",
        "            nout (int): Number of output features.\n",
        "            device (str): Device to store the tensors ('cpu' or 'cuda').\n",
        "        \"\"\"\n",
        "        self.W = torch.randn(nin, nout, device=device, requires_grad=False)\n",
        "        self.b = torch.zeros(nout, device=device, requires_grad=False)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Perform the forward pass of the linear layer.\n",
        "\n",
        "        Args:\n",
        "            X (torch.Tensor): Input tensor with shape (n_batch, nin).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with shape (n_batch, nout).\n",
        "        \"\"\"\n",
        "        ###########YOUR CODE HERE################################\n",
        "        self.X = X\n",
        "        Z = #code\n",
        "        return Z\n",
        "\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        Perform the backward pass of the linear layer.\n",
        "\n",
        "        Args:\n",
        "            dZ (torch.Tensor): Gradient of the loss with respect to the output of the linear layer.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Gradient of the loss with respect to the input of the linear layer.\n",
        "        \"\"\"\n",
        "        ###########YOUR CODE HERE################################\n",
        "        self.dW = #code\n",
        "        self.db = #code\n",
        "        self.dX = #code\n",
        "        return self.dX #What the net need to backpropagate\n",
        "\n",
        "    def update(self, lr):\n",
        "        \"\"\"\n",
        "        Update the weights and biases of the linear layer.\n",
        "\n",
        "        Args:\n",
        "            lr (float): Learning rate.\n",
        "        \"\"\"\n",
        "        ###########YOUR CODE HERE################################\n",
        "        self.W #code\n",
        "        self.b #code\n",
        "\n",
        "# Example usage\n",
        "nin = 4\n",
        "nout = 3\n",
        "n_batch = 5\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = 'cpu'\n",
        "# Simulated input tensor\n",
        "X = torch.randn(n_batch, nin).to(device)\n",
        "\n",
        "# Create an instance of the Linear class and compute the linear transformation\n",
        "net = Linear(nin, nout, device=device)\n",
        "Z = net.forward(X)\n",
        "print(Z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A20c5lPy8dCQ",
        "outputId": "14a1659d-c6df-4f07-ba00-d31907569561"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cross-Entropy Loss Exercise**\n",
        "\n",
        "In this exercise, you will implement the cross-entropy loss function, commonly used in classification tasks within neural networks. The cross-entropy loss measures the performance of a classification model whose output is a probability value between 0 and 1. You will be required to implement the forward pass to compute the loss and the backward pass to compute the gradient of the loss with respect to the input logits.\n",
        "\n",
        "## **Tasks**\n",
        "\n",
        "You need to implement the following methods in the `CrossEntropyFromLogits` class: `forward` and `backward`.\n",
        "\n",
        "### **Forward Pass**\n",
        "\n",
        "In the forward pass, the class computes the softmax probabilities, the log softmax, and then the cross-entropy loss. Given the input tensor $\\mathbf{Z}$ and the true labels $\\mathbf{Y}$, both of size $(n_{batch},n_{classes})$ we perform the following steps:\n",
        "\n",
        "1. **Softmax**: Compute the softmax probabilities:\n",
        "$$\\mathbf{A} = \\text{softmax}(\\mathbf{Z})$$\n",
        "\n",
        "2. **Log Softmax**: Compute the log softmax:\n",
        "$$\\text{log_softmax_Z} = \\log(\\text{softmax}(\\mathbf{Z}))$$\n",
        "\n",
        "3. **Log Probabilities**: Gather the log probabilities corresponding to the true labels:\n",
        "$$ \\text{log_probs} = \\text{log_softmax_Z}[\\text{range}(n_{\\text{batch}}), \\mathbf{Y}] $$\n",
        "\n",
        "4. **Cross-Entropy Loss**: Compute the cross-entropy loss:\n",
        "$$ \\text{loss} = -\\frac{1}{n_{\\text{batch}}} \\sum_{i=1}^{n_{\\text{batch}}} \\text{log_probs}_i $$\n",
        "\n",
        "where:\n",
        "- $\\mathbf{Z}$ is the input tensor with shape $(n_{\\text{batch}}, n_{\\text{classes}})$\n",
        "- $\\mathbf{Y}$ is the true labels tensor with shape $(n_{\\text{batch}},)$\n",
        "- $\\mathbf{A}$ is the softmax probabilities with shape $(n_{\\text{batch}}, n_{\\text{classes}})$\n",
        "- $\\text{log_softmax_Z}$ is the log softmax tensor with shape $(n_{\\text{batch}}, n_{\\text{classes}})$\n",
        "- $\\text{log_probs}$ is the log probabilities tensor with shape $(n_{\\text{batch}},)$\n",
        "- $\\text{loss} is the scalar cross-entropy loss\n",
        "\n",
        "### **Backward Pass**\n",
        "\n",
        "In the backward pass, we compute the gradient of the loss with respect to the input tensor $\\mathbf{Z}$. Given the softmax probabilities $\\mathbf{A}$ and the labels $\\mathbf{Y}$, we compute:\n",
        "\n",
        "$$\\mathbf{dZ} = \\mathbf{A} - \\mathbf{Y}_{\\text{one_hot}}$$\n",
        "\n",
        "where:\n",
        "- $\\mathbf{dZ}$ is the gradient of the loss with respect to $\\mathbf{Z}$, with shape $(n_{\\text{batch}}, n_{\\text{classes}})$\n",
        "- $\\mathbf{A}$ is the softmax probabilities with shape $(n_{\\text{batch}}, n_{\\text{classes}})$\n",
        "- $\\mathbf{Y}_{\\text{one_hot}}$ is the one-hot encoded true labels with shape $(n_{\\text{batch}}, n_{\\text{classes}})$\n",
        "\n",
        "The train loader returns labels as an array of size $n_{batch}$ where each value is an integer corresponding to the label of the sample. You need to one-hot-encode the labels.\n",
        "\n",
        "## **Instructions**\n",
        "\n",
        "1. **Forward Method**: Implement the forward pass by computing the softmax probabilities, log softmax, and cross-entropy loss.\n",
        "2. **Backward Method**: Implement the backward pass by computing the gradient of the loss with respect to the input tensor $\\mathbf{Z}$.\n",
        "\n",
        "Make sure to test your implementation with various input sizes to ensure it works correctly.\n",
        "\n"
      ],
      "metadata": {
        "id": "3-DpQ396RyJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossEntropyFromLogits:\n",
        "    \"\"\"\n",
        "    Class to perform the softmax operation.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, Z, Y):\n",
        "        \"\"\"\n",
        "        Perform the forward pass of the softmax function.\n",
        "\n",
        "        Args:\n",
        "            Z (torch.Tensor): Input tensor with shape (n_batch, n_classes).\n",
        "            Y (torch.Tensor): True labels with shape (n_batch, n_classes).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Cross-entropy loss\n",
        "        \"\"\"\n",
        "        self.Y = Y\n",
        "        # Compute the softmax probabilities (just for the backward)\n",
        "        self.A = torch.nn.functional.softmax(Z, dim=1)\n",
        "\n",
        "        # Compute log softmax\n",
        "        log_softmax_Z = torch.nn.functional.log_softmax(Z, dim=1)\n",
        "\n",
        "        # Gather the log probabilities corresponding to the true labels\n",
        "        log_probs = log_softmax_Z[torch.arange(Z.size(0)), Y] #(n_batch,)\n",
        "\n",
        "        # Compute the cross-entropy loss\n",
        "        loss = #code\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def backward(self, n_classes):\n",
        "        \"\"\"\n",
        "        Perform the backward pass of the softmax function.\n",
        "\n",
        "        Args:\n",
        "            n_classes: Needed to one-hot-encode the labels\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Gradient of the loss with respect to the input tensor.\n",
        "        \"\"\"\n",
        "        #########################YOUR CODE HERE#################################\n",
        "        dZ = #code\n",
        "        return dZ\n",
        "\n",
        "\n",
        "# Example usage\n",
        "nin = 4\n",
        "nout = 3\n",
        "n_batch = 5\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = 'cpu'\n",
        "# Simulated input tensor\n",
        "X = torch.randn(n_batch, nin).to(device)\n",
        "\n",
        "# Create an instance of the Linear class and compute the linear transformation\n",
        "net = Linear(nin, nout, device=device)\n",
        "Z = net.forward(X)\n",
        "\n",
        "\n",
        "CELoss = CrossEntropyFromLogits()\n",
        "Y = torch.randint(0, nout, (n_batch,))\n",
        "loss = CELoss.forward(Z, Y)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZYsEzaRBeKj",
        "outputId": "977e9043-b4ab-443b-c22b-be9a91911c49"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5930, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MNIST Classification**\n",
        "In this exercise, you will implement the a simple network composed of a linear layer and the cross-entropy loss function computed from the output of the linear layer. This combination is commonly used as the last layer in classification tasks within neural networks.\n",
        "\n",
        "We will use this implementation to train a model on the MNIST dataset, which consists of handwritten digits. The goal is to classify each image into one of the 10 digit classes (0-9).\n"
      ],
      "metadata": {
        "id": "gRwElc3LfIks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available and set the device accordingly\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = 'cpu'\n",
        "\n",
        "# Define the number of input features and output classes\n",
        "n_features = 784\n",
        "n_classes = 10\n",
        "\n",
        "# Initialize the network and loss function\n",
        "net = Linear(n_features, n_classes, device=device)\n",
        "CELoss = CrossEntropyFromLogits()\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "# List to store loss values for plotting\n",
        "Loss = []\n",
        "\n",
        "# Variables to accumulate accuracy\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "# Determine total number of batches\n",
        "total_batches = len(trainloader)\n",
        "\n",
        "# Training loop\n",
        "for batch_idx, (images, labels) in enumerate(tqdm(trainloader, desc=\"Training Batches\"), 1):\n",
        "    # Flatten the images and move them to the device\n",
        "    X = images.view(images.shape[0], -1).to(device)\n",
        "\n",
        "    # Forward pass: Compute predicted logits\n",
        "    Z = net.forward(X)\n",
        "\n",
        "    # Move labels to the device\n",
        "    Y = labels.to(device)\n",
        "\n",
        "    # Compute the cross-entropy loss\n",
        "    loss = CELoss.forward(Z, Y)\n",
        "\n",
        "    # Append the loss to the list\n",
        "    Loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    # Backward pass: Compute the gradients\n",
        "    dZ = CELoss.backward(n_classes)\n",
        "    dX = net.backward(dZ)\n",
        "\n",
        "    # Update the network parameters\n",
        "    net.update(learning_rate)\n",
        "\n",
        "    # Compute the accuracy for the current batch\n",
        "    _, predicted = torch.max(Z, 1)\n",
        "    correct = (predicted == Y).sum().item()\n",
        "    total_correct += correct\n",
        "    total_samples += Y.size(0)\n",
        "\n",
        "    # Print the loss and accuracy every 10% of the total batches\n",
        "    if batch_idx % (total_batches // 10) == 0:\n",
        "        accuracy = total_correct / total_samples\n",
        "        tqdm.write(f\"Batch {batch_idx}/{total_batches} - Loss: {loss.item():.4f}, Accumulated Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute and print the final accumulated accuracy\n",
        "accumulated_accuracy = total_correct / total_samples\n",
        "print(f\"Final Accumulated Accuracy: {accumulated_accuracy:.4f}\")\n",
        "\n",
        "# Plot the loss values\n",
        "plt.plot(np.array(Loss))\n",
        "plt.xlabel('Batch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TYINJm8iZakK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop\n",
        "for batch_idx, (images, labels) in enumerate(tqdm(testloader, desc=\"Testing Batches\"), 1):\n",
        "    # Flatten the images and move them to the device\n",
        "    X = images.view(images.shape[0], -1).to(device)\n",
        "\n",
        "    # Forward pass: Compute predicted logits\n",
        "    Z = net.forward(X)\n",
        "\n",
        "    # Move labels to the device\n",
        "    Y = labels.to(device)\n",
        "\n",
        "    # Compute the accuracy for the current batch\n",
        "    _, predicted = torch.max(Z, 1)\n",
        "    correct = (predicted == Y).sum().item()\n",
        "    total_correct += correct\n",
        "    total_samples += Y.size(0)\n",
        "\n",
        "    # Print the loss and accuracy every 10% of the total batches\n",
        "    if batch_idx % (total_batches // 10) == 0:\n",
        "        accuracy = total_correct / total_samples\n",
        "        tqdm.write(f\"Batch {batch_idx}/{total_batches}, Accumulated Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute and print the final accumulated accuracy\n",
        "accumulated_accuracy = total_correct / total_samples\n",
        "print(f\"Final Accumulated Accuracy: {accumulated_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRVMF7F2hqDV",
        "outputId": "3ddc8597-caf2-443a-e6e8-2d1e5037cef7"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing Batches:  68%|██████▊   | 107/157 [00:01<00:00, 79.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 93/938, Accumulated Accuracy: 0.7126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing Batches: 100%|██████████| 157/157 [00:01<00:00, 80.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accumulated Accuracy: 0.7196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Net Class Description**\n",
        "\n",
        "The `Net` class represents a neural network, allowing you to add layers and perform forward and backward passes through these layers. This class manages the sequence of layers and their interactions during training.\n",
        "\n",
        "### Class Methods\n",
        "\n",
        "The constructor initializes an empty list called `layers` to hold the different layers of the network.\n",
        "\n",
        "The add method appends a new layer to the network.\n",
        "\n",
        "The forward method performs the forward pass through all layers in the network. It takes an input tensor $\\mathbf{X} and sequentially applies each layer's forward method to it.\n",
        "\n",
        "The backward method performs the backward pass through all layers in the network in reverse order. It takes the gradient of the loss with respect to the output $\\mathbf{dZ}$ and sequentially applies each layer's backward method to it.\n",
        "\n",
        "The update method updates the parameters of all layers in the network using a given learning rate $\\alpha$.\n",
        "\n",
        "## **Tasks**\n",
        "\n",
        "You need to complete the implementation of the Net class by filling in the missing code for the forward, backward, and update methods.\n"
      ],
      "metadata": {
        "id": "s-YxmMx8g6ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the Net class.\n",
        "        This constructor initializes an empty list to hold the layers of the network.\n",
        "        \"\"\"\n",
        "        self.layers = []\n",
        "\n",
        "    def add(self, layer):\n",
        "        \"\"\"\n",
        "        Add a layer to the network.\n",
        "\n",
        "        Args:\n",
        "            layer: An instance of a layer (e.g., Linear) to be added to the network.\n",
        "        \"\"\"\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Perform the forward pass through all layers of the network.\n",
        "\n",
        "        Args:\n",
        "            X: Input tensor to the network.\n",
        "\n",
        "        Returns:\n",
        "            The output tensor after passing through all the layers.\n",
        "        \"\"\"\n",
        "        for layer in self.layers:\n",
        "            X = #code\n",
        "        return X\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        Perform the backward pass through all layers of the network.\n",
        "\n",
        "        Args:\n",
        "            dZ: Gradient of the loss with respect to the output of the network.\n",
        "\n",
        "        Returns:\n",
        "            The gradient of the loss with respect to the input of the network.\n",
        "        \"\"\"\n",
        "        for layer in reversed(self.layers):\n",
        "            dZ = #code\n",
        "        return dZ\n",
        "\n",
        "    def update(self, lr):\n",
        "        \"\"\"\n",
        "        Update the parameters of all layers in the network using the given learning rate.\n",
        "\n",
        "        Args:\n",
        "            lr: Learning rate for updating the parameters.\n",
        "        \"\"\"\n",
        "        for layer in self.layers:\n",
        "            #code"
      ],
      "metadata": {
        "id": "1imEUcxliTJK"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available and set the device accordingly\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# Forcing the device to CPU (this line will override the previous check)\n",
        "device = 'cpu'\n",
        "\n",
        "# Define the number of input features and output classes\n",
        "n_features = 784\n",
        "n_classes = 10\n",
        "\n",
        "# Initialize the network (assuming `Net` is a custom class that you've defined)\n",
        "net = Net()\n",
        "\n",
        "# Add a linear layer to the network with 784 input features and 1024 output features\n",
        "net.add(Linear(n_features, 1024, device=device))\n",
        "\n",
        "# Add another linear layer with 1024 input features and 10 output features\n",
        "net.add(Linear(1024, n_classes, device=device))\n",
        "\n",
        "# Initialize the custom cross-entropy loss function from logits\n",
        "CEloss = CrossEntropyFromLogits()"
      ],
      "metadata": {
        "id": "9Y0eoXyzjExZ"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the learning rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "# List to store loss values for plotting\n",
        "Loss = []\n",
        "\n",
        "# Variables to accumulate accuracy\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "# Determine total number of batches\n",
        "total_batches = len(trainloader)\n",
        "\n",
        "# Training loop\n",
        "for batch_idx, (images, labels) in enumerate(tqdm(trainloader, desc=\"Training Batches\"), 1):\n",
        "    # Flatten the images and move them to the device\n",
        "    X = images.view(images.shape[0], -1).to(device)\n",
        "\n",
        "    # Forward pass: Compute predicted logits\n",
        "    Z = net.forward(X)\n",
        "\n",
        "    # Move labels to the device\n",
        "    Y = labels.to(device)\n",
        "\n",
        "    # Compute the cross-entropy loss\n",
        "    loss = CELoss.forward(Z, Y)\n",
        "\n",
        "    # Append the loss to the list\n",
        "    Loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    # Backward pass: Compute the gradients\n",
        "    dZ = CELoss.backward(n_classes)\n",
        "    dX = net.backward(dZ)\n",
        "\n",
        "    # Update the network parameters\n",
        "    net.update(learning_rate)\n",
        "\n",
        "    # Compute the accuracy for the current batch\n",
        "    _, predicted = torch.max(Z, 1)\n",
        "    correct = (predicted == Y).sum().item()\n",
        "    total_correct += correct\n",
        "    total_samples += Y.size(0)\n",
        "\n",
        "    # Print the loss and accuracy every 10% of the total batches\n",
        "    if batch_idx % (total_batches // 10) == 0:\n",
        "        accuracy = total_correct / total_samples\n",
        "        tqdm.write(f\"Batch {batch_idx}/{total_batches} - Loss: {loss.item():.4f}, Accumulated Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute and print the final accumulated accuracy\n",
        "accumulated_accuracy = total_correct / total_samples\n",
        "print(f\"Final Accumulated Accuracy: {accumulated_accuracy:.4f}\")\n",
        "\n",
        "# Plot the loss values\n",
        "plt.plot(np.array(Loss))\n",
        "plt.xlabel('Batch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NqhIE7mKlTtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop\n",
        "for batch_idx, (images, labels) in enumerate(tqdm(testloader, desc=\"Testing Batches\"), 1):\n",
        "    # Flatten the images and move them to the device\n",
        "    X = images.view(images.shape[0], -1).to(device)\n",
        "\n",
        "    # Forward pass: Compute predicted logits\n",
        "    Z = net.forward(X)\n",
        "\n",
        "    # Move labels to the device\n",
        "    Y = labels.to(device)\n",
        "\n",
        "    # Compute the accuracy for the current batch\n",
        "    _, predicted = torch.max(Z, 1)\n",
        "    correct = (predicted == Y).sum().item()\n",
        "    total_correct += correct\n",
        "    total_samples += Y.size(0)\n",
        "\n",
        "    # Print the loss and accuracy every 10% of the total batches\n",
        "    if batch_idx % (total_batches // 10) == 0:\n",
        "        accuracy = total_correct / total_samples\n",
        "        tqdm.write(f\"Batch {batch_idx}/{total_batches}, Accumulated Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute and print the final accumulated accuracy\n",
        "accumulated_accuracy = total_correct / total_samples\n",
        "print(f\"Final Accumulated Accuracy: {accumulated_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "JeLmd0hUnlJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ReLU Activation Layer Exercise**\n",
        "\n",
        "In this exercise, you will implement the ReLU (Rectified Linear Unit) activation function, commonly used in neural networks. ReLU introduces non-linearity into the model, which helps the network learn complex patterns. You will be required to implement the forward pass to apply the ReLU function and the backward pass to compute the gradient of the loss with respect to the input.\n",
        "\n",
        "### Class Methods\n",
        "\n",
        "#### `ReLU`\n",
        "The `ReLU` class represents the ReLU activation function, containing methods to perform the forward and backward passes.\n",
        "\n",
        "#### `forward`\n",
        "The `forward` method applies the ReLU activation function element-wise to the input tensor \\(\\mathbf{Z}\\).\n",
        "\n",
        "### **Tasks**\n",
        "\n",
        "You need to complete the implementation of the ReLU class by filling in the missing code for the forward and backward methods.\n"
      ],
      "metadata": {
        "id": "mzOgjgSoirlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    \"\"\"\n",
        "    ReLU activation layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, Z):\n",
        "        \"\"\"\n",
        "        Perform the forward pass of the ReLU activation function.\n",
        "\n",
        "        Args:\n",
        "            X (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with ReLU applied element-wise.\n",
        "        \"\"\"\n",
        "        self.A = #code\n",
        "        return self.A\n",
        "\n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        Perform the backward pass of the ReLU activation function.\n",
        "\n",
        "        Args:\n",
        "            dA (torch.Tensor): Gradient of the loss with respect to the output.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Gradient of the loss with respect to the input.\n",
        "        \"\"\"\n",
        "        dZ = #code\n",
        "        return dZ\n",
        "\n",
        "    def update(self,lr):\n",
        "        \"\"\"\n",
        "        ReLU does not have any parameters to update.\n",
        "        \"\"\"\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "tmEUvk1dod-N"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available and set the device accordingly\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# Forcing the device to CPU (this line will override the previous check)\n",
        "device = 'cpu'\n",
        "\n",
        "# Define the number of input features and output classes\n",
        "n_features = 784\n",
        "n_classes = 10\n",
        "\n",
        "# Initialize the network (assuming `Net` is a custom class that you've defined)\n",
        "net = Net()\n",
        "\n",
        "# Add a linear layer to the network with 784 input features and 1024 output features\n",
        "net.add(Linear(n_features, 1024, device=device))\n",
        "\n",
        "# Add a non-linear activation function\n",
        "net.add(ReLU())\n",
        "\n",
        "# Add another linear layer with 1024 input features and 10 output features\n",
        "net.add(Linear(1024, n_classes, device=device))\n",
        "\n",
        "# Initialize the custom cross-entropy loss function from logits\n",
        "CEloss = CrossEntropyFromLogits()"
      ],
      "metadata": {
        "id": "rRQxxSRlph7k"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the learning rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "# List to store loss values for plotting\n",
        "Loss = []\n",
        "\n",
        "# Variables to accumulate accuracy\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "# Determine total number of batches\n",
        "total_batches = len(trainloader)\n",
        "\n",
        "# Training loop\n",
        "for batch_idx, (images, labels) in enumerate(tqdm(trainloader, desc=\"Training Batches\"), 1):\n",
        "    # Flatten the images and move them to the device\n",
        "    X = images.view(images.shape[0], -1).to(device)\n",
        "\n",
        "    # Forward pass: Compute predicted logits\n",
        "    Z = net.forward(X)\n",
        "\n",
        "    # Move labels to the device\n",
        "    Y = labels.to(device)\n",
        "\n",
        "    # Compute the cross-entropy loss\n",
        "    loss = CELoss.forward(Z, Y)\n",
        "\n",
        "    # Append the loss to the list\n",
        "    Loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    # Backward pass: Compute the gradients\n",
        "    dZ = CELoss.backward(n_classes)\n",
        "    dX = net.backward(dZ)\n",
        "\n",
        "    # Update the network parameters\n",
        "    net.update(learning_rate)\n",
        "\n",
        "    # Compute the accuracy for the current batch\n",
        "    _, predicted = torch.max(Z, 1)\n",
        "    correct = (predicted == Y).sum().item()\n",
        "    total_correct += correct\n",
        "    total_samples += Y.size(0)\n",
        "\n",
        "    # Print the loss and accuracy every 10% of the total batches\n",
        "    if batch_idx % (total_batches // 10) == 0:\n",
        "        accuracy = total_correct / total_samples\n",
        "        tqdm.write(f\"Batch {batch_idx}/{total_batches} - Loss: {loss.item():.4f}, Accumulated Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute and print the final accumulated accuracy\n",
        "accumulated_accuracy = total_correct / total_samples\n",
        "print(f\"Final Accumulated Accuracy: {accumulated_accuracy:.4f}\")\n",
        "\n",
        "# Plot the loss values\n",
        "plt.plot(np.array(Loss))\n",
        "plt.xlabel('Batch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xCBYBn9Dp5mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop\n",
        "for batch_idx, (images, labels) in enumerate(tqdm(testloader, desc=\"Testing Batches\"), 1):\n",
        "    # Flatten the images and move them to the device\n",
        "    X = images.view(images.shape[0], -1).to(device)\n",
        "\n",
        "    # Forward pass: Compute predicted logits\n",
        "    Z = net.forward(X)\n",
        "\n",
        "    # Move labels to the device\n",
        "    Y = labels.to(device)\n",
        "\n",
        "    # Compute the accuracy for the current batch\n",
        "    _, predicted = torch.max(Z, 1)\n",
        "    correct = (predicted == Y).sum().item()\n",
        "    total_correct += correct\n",
        "    total_samples += Y.size(0)\n",
        "\n",
        "    # Print the loss and accuracy every 10% of the total batches\n",
        "    if batch_idx % (total_batches // 10) == 0:\n",
        "        accuracy = total_correct / total_samples\n",
        "        tqdm.write(f\"Batch {batch_idx}/{total_batches}, Accumulated Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute and print the final accumulated accuracy\n",
        "accumulated_accuracy = total_correct / total_samples\n",
        "print(f\"Final Accumulated Accuracy: {accumulated_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "WrIpeOWvwiZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}