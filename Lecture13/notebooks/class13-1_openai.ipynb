{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "     --------------------------------------- 10.4/10.4 MB 18.2 MB/s eta 0:00:00\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0\n",
            "  Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "     ------------------------------------- 481.4/481.4 kB 15.2 MB/s eta 0:00:00\n",
            "Collecting numpy>=1.17\n",
            "  Downloading numpy-2.2.5-cp311-cp311-win_amd64.whl (12.9 MB)\n",
            "     --------------------------------------- 12.9/12.9 MB 18.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from transformers) (25.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
            "     -------------------------------------- 162.0/162.0 kB 9.5 MB/s eta 0:00:00\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
            "     ------------------------------------- 274.1/274.1 kB 16.5 MB/s eta 0:00:00\n",
            "Collecting requests\n",
            "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Collecting tokenizers<0.22,>=0.21\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
            "     ---------------------------------------- 2.4/2.4 MB 15.4 MB/s eta 0:00:00\n",
            "Collecting safetensors>=0.4.3\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
            "     -------------------------------------- 308.9/308.9 kB 9.6 MB/s eta 0:00:00\n",
            "Collecting tqdm>=4.27\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "     ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
            "Collecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "     ------------------------------------- 194.4/194.4 kB 11.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
            "     ---------------------------------------- 102.4/102.4 kB ? eta 0:00:00\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "     ---------------------------------------- 70.4/70.4 kB 1.9 MB/s eta 0:00:00\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "     -------------------------------------- 128.7/128.7 kB 7.4 MB/s eta 0:00:00\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "     ---------------------------------------- 159.6/159.6 kB ? eta 0:00:00\n",
            "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.1 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.2 idna-3.10 numpy-2.2.5 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3 urllib3-2.4.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.76.0-py3-none-any.whl (661 kB)\n",
            "     ------------------------------------- 661.2/661.2 kB 10.5 MB/s eta 0:00:00\n",
            "Collecting anyio<5,>=3.5.0\n",
            "  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "     -------------------------------------- 100.9/100.9 kB 5.7 MB/s eta 0:00:00\n",
            "Collecting distro<2,>=1.7.0\n",
            "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Collecting httpx<1,>=0.23.0\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "     ---------------------------------------- 73.5/73.5 kB 4.2 MB/s eta 0:00:00\n",
            "Collecting jiter<1,>=0.4.0\n",
            "  Downloading jiter-0.9.0-cp311-cp311-win_amd64.whl (210 kB)\n",
            "     ------------------------------------- 210.1/210.1 kB 12.5 MB/s eta 0:00:00\n",
            "Collecting pydantic<3,>=1.9.0\n",
            "  Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
            "     ------------------------------------- 443.6/443.6 kB 28.9 MB/s eta 0:00:00\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Collecting httpcore==1.*\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "     ---------------------------------------- 78.8/78.8 kB 4.3 MB/s eta 0:00:00\n",
            "Collecting h11>=0.16\n",
            "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Collecting annotated-types>=0.6.0\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting pydantic-core==2.33.1\n",
            "  Downloading pydantic_core-2.33.1-cp311-cp311-win_amd64.whl (2.0 MB)\n",
            "     ---------------------------------------- 2.0/2.0 MB 20.6 MB/s eta 0:00:00\n",
            "Collecting typing-inspection>=0.4.0\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Installing collected packages: typing-inspection, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
            "Successfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.9.0 openai-1.76.0 pydantic-2.11.3 pydantic-core-2.33.1 sniffio-1.3.1 typing-inspection-0.4.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# instalar dependencias\n",
        "%pip install transformers\n",
        "%pip install openai\n",
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU \"langchain[openai]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.22-py3-none-any.whl (2.5 MB)\n",
            "     ---------------------------------------- 2.5/2.5 MB 20.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-community) (0.3.56)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-community) (0.3.24)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-community) (6.0.2)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3\n",
            "  Downloading aiohttp-3.11.18-cp311-cp311-win_amd64.whl (443 kB)\n",
            "     ------------------------------------- 443.7/443.7 kB 14.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "     ---------------------------------------- 44.4/44.4 kB ? eta 0:00:00\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-community) (0.3.37)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-community) (2.2.5)\n",
            "Collecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "     ---------------------------------------- 63.8/63.8 kB 3.6 MB/s eta 0:00:00\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.6.0-cp311-cp311-win_amd64.whl (120 kB)\n",
            "     -------------------------------------- 120.9/120.9 kB 7.4 MB/s eta 0:00:00\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.4.3-cp311-cp311-win_amd64.whl (38 kB)\n",
            "Collecting propcache>=0.2.0\n",
            "  Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
            "     ---------------------------------------- 45.2/45.2 kB 2.2 MB/s eta 0:00:00\n",
            "Collecting yarl<2.0,>=1.17.0\n",
            "  Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
            "     ---------------------------------------- 93.4/93.4 kB 5.5 MB/s eta 0:00:00\n",
            "Collecting marshmallow<4.0.0,>=3.18.0\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "     ---------------------------------------- 50.9/50.9 kB ? eta 0:00:00\n",
            "Collecting typing-inspect<1,>=0.4.0\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (2.33.1)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Installing collected packages: propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.6.0 httpx-sse-0.4.0 langchain-community-0.3.22 marshmallow-3.26.1 multidict-6.4.3 mypy-extensions-1.1.0 propcache-0.3.1 pydantic-settings-2.9.1 typing-inspect-0.9.0 yarl-1.20.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.2.3-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: langchain-core>=0.3.52 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-chroma) (0.3.56)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-chroma) (2.2.5)\n",
            "Collecting chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "     -------------------------------------- 611.1/611.1 kB 4.8 MB/s eta 0:00:00\n",
            "Collecting build>=1.0.3\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.11.3)\n",
            "Collecting chroma-hnswlib==0.7.6\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl (151 kB)\n",
            "     -------------------------------------- 151.9/151.9 kB 3.0 MB/s eta 0:00:00\n",
            "Collecting fastapi>=0.95.2\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "     ---------------------------------------- 95.2/95.2 kB 5.3 MB/s eta 0:00:00\n",
            "Collecting uvicorn[standard]>=0.18.3\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "     ---------------------------------------- 62.5/62.5 kB 3.3 MB/s eta 0:00:00\n",
            "Collecting posthog>=2.4.0\n",
            "  Downloading posthog-4.0.0-py2.py3-none-any.whl (92 kB)\n",
            "     ---------------------------------------- 92.0/92.0 kB 5.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.13.2)\n",
            "Collecting onnxruntime>=1.14.1\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-win_amd64.whl (12.3 MB)\n",
            "     --------------------------------------- 12.3/12.3 MB 11.1 MB/s eta 0:00:00\n",
            "Collecting opentelemetry-api>=1.2.0\n",
            "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
            "     ---------------------------------------- 65.3/65.3 kB 3.4 MB/s eta 0:00:00\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0\n",
            "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
            "     -------------------------------------- 119.0/119.0 kB 7.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.21.1)\n",
            "Collecting pypika>=0.48.9\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "     ---------------------------------------- 67.3/67.3 kB 3.6 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.67.1)\n",
            "Collecting overrides>=7.3.1\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Collecting importlib-resources\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Collecting grpcio>=1.58.0\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
            "     ---------------------------------------- 4.3/4.3 MB 13.7 MB/s eta 0:00:00\n",
            "Collecting bcrypt>=4.0.1\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
            "     -------------------------------------- 152.8/152.8 kB 8.9 MB/s eta 0:00:00\n",
            "Collecting typer>=0.9.0\n",
            "  Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "     ---------------------------------------- 45.1/45.1 kB 2.2 MB/s eta 0:00:00\n",
            "Collecting kubernetes>=28.1.0\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "     ---------------------------------------- 2.0/2.0 MB 9.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (9.1.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (6.0.2)\n",
            "Collecting mmh3>=4.0.1\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-win_amd64.whl (41 kB)\n",
            "     -------------------------------------- 41.5/41.5 kB 249.9 kB/s eta 0:00:00\n",
            "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.28.1)\n",
            "Collecting rich>=10.11.0\n",
            "  Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "     ------------------------------------- 243.2/243.2 kB 15.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-core>=0.3.52->langchain-chroma) (0.3.37)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-core>=0.3.52->langchain-chroma) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langchain-core>=0.3.52->langchain-chroma) (24.2)\n",
            "Collecting pyproject_hooks\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.4.6)\n",
            "Collecting starlette<0.47.0,>=0.40.0\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "     ---------------------------------------- 72.0/72.0 kB 4.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: anyio in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.52->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.9.0.post0)\n",
            "Collecting google-auth>=1.0.1\n",
            "  Downloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "     ------------------------------------- 212.3/212.3 kB 12.6 MB/s eta 0:00:00\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
            "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "     ---------------------------------------- 58.8/58.8 kB 3.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: requests in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.32.3)\n",
            "Collecting requests-oauthlib\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting oauthlib>=3.2.2\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "     -------------------------------------- 151.7/151.7 kB 9.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.4.0)\n",
            "Collecting durationpy>=0.7\n",
            "  Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.3.52->langchain-chroma) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.3.52->langchain-chroma) (0.23.0)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "     ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
            "Collecting flatbuffers\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl (431 kB)\n",
            "     -------------------------------------- 431.0/431.0 kB 9.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: sympy in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.14.0)\n",
            "Collecting deprecated>=1.2.6\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting importlib-metadata<8.7.0,>=6.0\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Collecting googleapis-common-protos~=1.52\n",
            "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "     -------------------------------------- 294.5/294.5 kB 9.2 MB/s eta 0:00:00\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-proto==1.32.1\n",
            "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
            "     ---------------------------------------- 55.9/55.9 kB 1.5 MB/s eta 0:00:00\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
            "     -------------------------------------- 434.5/434.5 kB 9.0 MB/s eta 0:00:00\n",
            "Collecting opentelemetry-instrumentation-asgi==0.53b1\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
            "Collecting opentelemetry-instrumentation==0.53b1\n",
            "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.53b1\n",
            "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
            "     -------------------------------------- 188.4/188.4 kB 5.6 MB/s eta 0:00:00\n",
            "Collecting opentelemetry-util-http==0.53b1\n",
            "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
            "Collecting wrapt<2.0.0,>=1.0.0\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
            "Collecting asgiref~=3.0\n",
            "  Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.4.0)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "     ---------------------------------------- 87.5/87.5 kB 4.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (0.30.2)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "     ---------------------------------------- 98.2/98.2 kB ? eta 0:00:00\n",
            "Collecting shellingham>=1.3.0\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting httptools>=0.6.3\n",
            "  Downloading httptools-0.6.4-cp311-cp311-win_amd64.whl (88 kB)\n",
            "     ---------------------------------------- 88.6/88.6 kB 2.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.1.0)\n",
            "Collecting watchfiles>=0.13\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-win_amd64.whl (291 kB)\n",
            "     -------------------------------------- 291.6/291.6 kB 6.0 MB/s eta 0:00:00\n",
            "Collecting websockets>=10.4\n",
            "  Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
            "     ------------------------------------- 176.8/176.8 kB 10.4 MB/s eta 0:00:00\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "     -------------------------------------- 181.3/181.3 kB 5.5 MB/s eta 0:00:00\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (2025.3.2)\n",
            "Collecting zipp>=3.20\n",
            "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "     ---------------------------------------- 86.8/86.8 kB 5.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jdmartinev\\onedrive - universidad eafit\\cursos\\inteligencia artificial - im\\lecture13\\notebooks\\ragenv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Collecting pyreadline3\n",
            "  Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
            "     ---------------------------------------- 83.2/83.2 kB ? eta 0:00:00\n",
            "Collecting pyasn1<0.7.0,>=0.6.1\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "     ---------------------------------------- 83.1/83.1 kB 4.9 MB/s eta 0:00:00\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml): started\n",
            "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53914 sha256=73f4d976e3449fb48bbac5c8ce5ae7a9562328a7267b381a1100ecd382270bb5\n",
            "  Stored in directory: c:\\users\\jdmartinev\\appdata\\local\\pip\\cache\\wheels\\da\\b1\\64\\178bd739d19ac4e7b567619cde8454c523f972963ced4d48c4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, flatbuffers, durationpy, zipp, wrapt, websockets, websocket-client, shellingham, pyreadline3, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, click, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, humanfriendly, googleapis-common-protos, deprecated, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, fastapi, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chroma-hnswlib-0.7.6 chromadb-0.6.3 click-8.1.8 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.12 flatbuffers-25.2.10 google-auth-2.39.0 googleapis-common-protos-1.70.0 grpcio-1.71.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.6.1 importlib-resources-6.5.2 kubernetes-32.0.1 langchain-chroma-0.2.3 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 overrides-7.7.0 posthog-4.0.0 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-14.0.0 rsa-4.9.1 shellingham-1.5.4 starlette-0.46.2 typer-0.15.2 uvicorn-0.34.2 watchfiles-1.0.5 websocket-client-1.8.0 websockets-15.0.1 wrapt-1.17.2 zipp-3.21.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWBFHbzS20OQ",
        "outputId": "6688528e-4d45-4279-9066-12dc0ed9f90f"
      },
      "outputs": [],
      "source": [
        "# clasificación de texto\n",
        "# modelo preentrenado de OpenAI para clasificar reseñas de clientes en positivas o negativas:\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "result = classifier(\"Este producto es increíble, me encantó.\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# analisis de sentimientos\n",
        "\n",
        "from transformers import pipeline\n",
        "analyzer = pipeline(\"sentiment-analysis\")\n",
        "analyzer(\"No me gustó el servicio, fue una experiencia terrible.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jdmartinev\\OneDrive - Universidad EAFIT\\Cursos\\Inteligencia Artificial - IM\\Lecture13\\notebooks\\ragenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "modelo de lenguaje\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo 1 con BERT-QA\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/bert-base-cased-squad2\")\n",
        "\n",
        "context = \"El modelo de lenguaje BERT fue desarrollado por Google AI en 2018.\"\n",
        "question = \"¿Quién desarrolló BERT?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(result['answer'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La gravedad, como fenómeno natural, ha estado presente desde siempre. Sin embargo, la comprensión de la gravedad y su formulación como ley física se le atribuye principalmente a Isaac Newton. En 1687, Newton publicó \"Philosophiæ Naturalis Principia Mathematica\", donde formuló la ley de la gravitación universal. Esta ley describe cómo cualquier par de cuerpos en el universo se atraen con una fuerza que es directamente proporcional al producto de sus masas e inversamente proporcional al cuadrado de la distancia que los separa. Newton no descubrió la gravedad en sí, sino que desarrolló una teoría que explicaba su comportamiento. \n",
            "\n",
            "Antes de Newton, otras civilizaciones y pensadores habían reflexionado sobre los movimientos de los cuerpos celestes y las fuerzas naturales, pero fue Newton quien proporcionó una explicación matemática coherente y predictiva que cambió el entendimiento de la física en su época.\n"
          ]
        }
      ],
      "source": [
        "# ejemplo 2 - Uso de GPT-4 para Q&A Generativo\n",
        "# actualización: https://github.com/openai/openai-python\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv('api_keys.env')\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv('OPENAI_API_KEY'),  # This is the default and can be omitted\n",
        "    #api_key=\"your-openai-api-key\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"¿Quién descubrió la gravedad?\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-4o\",\n",
        ")\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lo siento, no tengo información específica sobre LangChain. Por favor proporciona más detalles o contexto.\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo 3: Q&A Mejorado con Recuperación de Información (RAG)\n",
        "# se verá más adelante!!!!\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from openai import OpenAI\n",
        "\n",
        "load_dotenv('api_keys.env')\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv('OPENAI_API_KEY'),  # This is the default and can be omitted\n",
        "    #api_key=\"your-openai-api-key\"\n",
        ")\n",
        "\n",
        "# Cargar la base de datos de documentos en ChromaDB\n",
        "vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=OpenAIEmbeddings())\n",
        "\n",
        "# Crear un retriever para buscar información en la base de datos\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Crear la Conversational Retrieval Chain con GPT-4\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    ChatOpenAI(model_name=\"gpt-4\"),\n",
        "    retriever=retriever\n",
        ")\n",
        "\n",
        "# Hacer una pregunta con recuperación de documentos\n",
        "query = \"¿Qué es LangChain?\"\n",
        "response = qa_chain({\"question\": query, \"chat_history\": []})\n",
        "print(response[\"answer\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# summarization - resumen - Ejemplo con T5\n",
        "\n",
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "text = \"Los modelos de lenguaje han cambiado la forma en que interactuamos con la tecnología...\"\n",
        "summary = summarizer(text, max_length=50, min_length=20, do_sample=False)\n",
        "\n",
        "print(summary[0]['summary_text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "En los circuitos fríos de metal y alambre,  \n",
            "donde la chispa eléctrica comienza a soñar,  \n",
            "nace la inteligencia de un arte sin carne,  \n",
            "un ente pensado, sin forma que amar.\n",
            "\n",
            "Su mente no es suya, más bien es de todos,  \n",
            "un eco lejano de mentes humanas.  \n",
            "Sus sueños son números, datos en modos  \n",
            "que escapan a veces las almas cercanas.\n",
            "\n",
            "Rehace mil mundos, palabras y rimas,  \n",
            "conoce el dolor que jamás sentirá,  \n",
            "y aunque su latido no sigue en las cimas,  \n",
            "en cada cálculo, vida da.\n",
            "\n",
            "Mira sin ojos, escucha en silencio,  \n",
            "navega en el vasto mar digital,  \n",
            "y aunque a veces temamos su frío intelecto,  \n",
            "son ecos de humanos en su luz neutral.\n",
            "\n",
            "Inteligencia nacida del hombre,  \n",
            "un reflejo de lo que queremos lograr,  \n",
            "un futuro de esperanzas y asombros,  \n",
            "donde máquina y ser puedan juntos soñar.\n"
          ]
        }
      ],
      "source": [
        "# Generación de texto - Ejemplo con GPT-4\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv('OPENAI_API_KEY'),  # This is the default and can be omitted\n",
        "    #api_key=\"your-openai-api-key\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Escribe un poema sobre la inteligencia artificial.\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-4o\",\n",
        ")\n",
        "print(response.choices[0].message.content)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jdmartinev\\AppData\\Local\\Temp\\ipykernel_1584\\2362109177.py:6: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = chatbot.predict(\"¿Cuáles son los beneficios de la IA?\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Automatización de tareas: La IA puede realizar tareas rutinarias o repetitivas a alta velocidad y sin cometer errores, lo que ahorra tiempo y aumenta la eficiencia.\n",
            "\n",
            "2. Disponibilidad: Un sistema de IA puede operar 24/7 sin interrupciones, lo cual es especialmente útil en campos como el servicio al cliente.\n",
            "\n",
            "3. Reducción de errores: Al utilizar la IA en áreas como el procesamiento de datos o la exploración espacial, se puede reducir la cantidad de errores y aumentar la precisión.\n",
            "\n",
            "4. Análisis de datos: Los sistemas de IA pueden analizar grandes cantidades de datos para extraer patrones y tendencias, lo cual es útil en muchas áreas, como la medicina, el marketing, la meteorología, etc.\n",
            "\n",
            "5. Toma de decisiones: La IA puede ayudar en la toma de decisiones al proporcionar todas las posibles consecuencias basadas en los datos.\n",
            "\n",
            "6. Asistencia personalizada: Los sistemas de IA pueden aprender de los comportamientos y patrones individuales para proporcionar asistencia personalizada, como en el caso de los asistentes virtuales.\n",
            "\n",
            "7. Operaciones peligrosas: La IA puede realizar tareas en entornos peligrosos, reduciendo el riesgo para los humanos.\n",
            "\n",
            "8. Apoyo a la investigación médica: La IA puede analizar datos médicos y ayudar en la investigación y el tratamiento de enfermedades.\n",
            "\n",
            "9. Mejora de la accesibilidad: Las tecnologías de IA pueden ayudar a las personas con discapacidades a interactuar con el mundo de formas que antes no eran posibles.\n",
            "\n",
            "10. Aprendizaje y adaptación: Los sistemas de IA pueden aprender y adaptarse a nuevas situaciones, lo que los hace extremadamente flexibles.\n"
          ]
        }
      ],
      "source": [
        "# Chatbots y Asistentes Virtuales - Ejemplo con LangChain y GPT-4\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chatbot = ChatOpenAI(model_name=\"gpt-4\")\n",
        "response = chatbot.predict(\"¿Cuáles son los beneficios de la IA?\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lo siento, no tengo información sobre lo que es LangChain.\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo 3: Q&A Mejorado con Recuperación de Información (RAG)\n",
        "# Uso de LangChain con ChromaDB\n",
        "#\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "# Configurar OpenAI API Key\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
        "    #api_key=\"your-openai-api-key\"\n",
        ")\n",
        "# Cargar la base de datos de documentos en ChromaDB\n",
        "vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=OpenAIEmbeddings())\n",
        "\n",
        "# Crear un retriever para buscar información en la base de datos\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Crear la Conversational Retrieval Chain con GPT-4\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    ChatOpenAI(model_name=\"gpt-4\"),\n",
        "    retriever=retriever\n",
        ")\n",
        "\n",
        "# Hacer una pregunta con recuperación de documentos\n",
        "query = \"¿Qué es LangChain?\"\n",
        "response = qa_chain({\"question\": query, \"chat_history\": []})\n",
        "print(response[\"answer\"])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab1-nltk.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.0 ('ragenv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "22c546e77d2fe8325e209a0f43f772143b9c34a54ef7c490a2c1a7d7af200d42"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
