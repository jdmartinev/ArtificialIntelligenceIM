{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOF7b9okUGKeOvqnSDoagLe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## From-Scratch “MiniTorch” — Notebook Overview\n","\n","In this notebook we will **implement a minimal deep-learning framework from scratch** (“miniTorch”) and use it to train a simple neural network on the **MNIST** dataset as a toy problem.\n","\n","### Objectives\n","- **Layers:** Implement core layers (e.g., `Linear`, `Dropout`, `BatchNorm1D`) with clean APIs.\n","- **Forward & Backward:** Write explicit **forward** and **backward** passes for every layer (no autograd).\n","- **Losses:** Implement a **cross-entropy from logits** loss.\n","- **Training Loop:** Build an epoch-based loop with **train/validation** splits and metrics.\n","- **Optimization:** Perform **manual SGD** parameter updates (learning rate, gradient averaging, etc.).\n","\n","### Scope & Assumptions\n","- We will **not** use PyTorch autograd; gradients are computed **manually**.\n","- Tensors are used only as numerical containers and for basic ops (matmul, sum, etc.).\n","- We adopt PyTorch-style `net.train()` / `net.eval()` mode switches for realism.\n","- The dataset is **MNIST** (28×28 grayscale digits, 10 classes), serving as a **toy setting** to validate our implementation.\n","\n","### What You’ll Get By the End\n","- A working “miniTorch” stack: layers → forward/backward → training loop → optimizer.\n","- Clear, student-friendly code that mirrors real libraries while remaining small and inspectable.\n","\n"],"metadata":{"id":"GTp5HHtW98dK"}},{"cell_type":"markdown","source":["## 1. Loading the MNIST Dataset\n","\n","We will use the **MNIST** dataset — a classic benchmark of **28×28 grayscale images** of handwritten digits (0–9).  \n","It contains:\n","- **60,000** training images\n","- **10,000** test images\n","\n","### Steps:\n","1. **Download & Transform**  \n","   - Use `torchvision.datasets.MNIST` to automatically download the data.\n","   - Convert images to tensors and normalize pixel values to the range \\([-1, 1]\\).\n","\n","2. **Split into Train & Validation**  \n","   - The official training set (60,000 samples) will be split into:\n","     - **Training set:** 80% of the data (48,000 images).\n","     - **Validation set:** 20% of the data (12,000 images).\n","   - The split allows us to monitor generalization during training.\n","\n","3. **Test Set**  \n","   - The test set (10,000 images) is kept separate and **only used at the end** to report final performance.\n","\n","### Why Split into Validation?\n","The validation set helps track **overfitting**:  \n","- If training accuracy keeps increasing but validation accuracy stalls or decreases, the model is memorizing instead of generalizing.\n","\n","### Summary\n","- **Training set:** update model weights.\n","- **Validation set:** tune hyperparameters & monitor generalization.\n","- **Test set:** final unbiased evaluation.\n"],"metadata":{"id":"VIe_sdxH-kZ-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"09Qu96B35Wdu"},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","from matplotlib import gridspec\n","from sklearn.datasets import make_classification\n","import numpy as np\n","# pick the seed for reproducibility - change it to explore the effects of random variations\n","np.random.seed(0)\n","import random\n","from tqdm import tqdm\n","from torch.utils.data import random_split"]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms"],"metadata":{"id":"TlUCB_zK6Scx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define transform\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","# Load full train dataset\n","full_trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","\n","# Split into train and validation\n","train_size = int(0.8 * len(full_trainset))\n","val_size = len(full_trainset) - train_size\n","trainset, valset = random_split(full_trainset, [train_size, val_size])\n","\n","# DataLoaders\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)\n","\n","# Test data\n","testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"],"metadata":{"id":"TIBpYf996Zit"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example: Iterate over a few batches\n","for images, labels in trainloader:\n","    print(images.shape, labels.shape)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-t4LZI997v-6","executionInfo":{"status":"ok","timestamp":1755027165406,"user_tz":300,"elapsed":38,"user":{"displayName":"Juan David Martinez Vargas","userId":"15315348669826032119"}},"outputId":"e31049c8-5989-441d-f295-ba89a8ec92d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 1, 28, 28]) torch.Size([64])\n"]}]},{"cell_type":"code","source":["# Check some examples\n","for images, labels in trainloader:\n","    # Denormalize the images for plotting\n","    images = images * 0.5 + 0.5\n","\n","    # Plot the images\n","    plt.figure(figsize=(10, 10))\n","    for i in range(9):  # Plot 9 images\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(images[i][0], cmap='gray')  # images[i][0] for grayscale images\n","        plt.title(f\"Label: {labels[i].item()}\")\n","        plt.axis('off')\n","    plt.show()\n","    break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":829},"id":"UqqrP50f75ns","executionInfo":{"status":"ok","timestamp":1755027168052,"user_tz":300,"elapsed":514,"user":{"displayName":"Juan David Martinez Vargas","userId":"15315348669826032119"}},"outputId":"5eed2234-9e7a-46b5-856a-9c0ef4537c04"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x1000 with 9 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAxkAAAMsCAYAAAA4VG/hAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARqJJREFUeJzt3Xu8lmPeN/7vap8kSmUziaYYjcwY22kyRUwhI2MTxqbH9g4zeGwGg8zY76Yed5jG3oPxjJRtN3MbZfCYbMcIkQhRKilFW12/P+anZ0wc51quY22u1fv9evWH63Ne5/ldy1pH69NZ51FVKpVKAQAAkEmT+h4AAABoXJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACArJQMAAMhKyQAAALJSMgAAgKyUjAo1ffr0qKqqiiuvvDLbOSdOnBhVVVUxceLEbOcEGi7rCFAOawgpSkYduuWWW6Kqqiqee+65+h6lVowdOzaGDBkS3bp1i7XWWiu22GKLOPXUU2P+/Pn1PRo0Go19Hfl3u+++e1RVVcWJJ55Y36NAo7AmrCF33XVX/OAHP4hWrVpFx44d46ijjoq5c+fW91hrHCWDbI499th47bXX4tBDD42rr746Bg4cGKNGjYof/vCHsXjx4voeD6gwY8eOjaeffrq+xwAqyHXXXRcHH3xwtG/fPn73u9/FMcccE3fddVf0798/lixZUt/jrVGa1fcANB5jxoyJfv36fem1bbfdNo444oi444474uijj66fwYCKs2TJkjj11FPjV7/6VZx33nn1PQ5QAZYtWxZnn312/PjHP47//u//jqqqqoiI6N27d+y9995x/fXXxy9+8Yt6nnLN4U5GA7Ns2bI477zzYtttt4127dpFmzZtYuedd44JEyZ87XtGjBgRXbt2jdatW0ffvn1j8uTJqx0zZcqU2H///aN9+/bRqlWr2G677eL+++8vnOezzz6LKVOmVOs2478XjIiIfffdNyIiXnvttcL3A3lU8jryhcsvvzxWrlwZp512WrXfA+RRqWvI5MmTY/78+TFkyJBVBSMiYtCgQbH22mvHXXfdVXgt8lEyGphPPvkkbrjhhujXr19cdtllcf7558ecOXNiwIAB8fe//32142+77ba4+uqr44QTToizzjorJk+eHLvuumt8+OGHq4555ZVXYqeddorXXnstzjzzzLjqqquiTZs2MXjw4Bg3blxynmeeeSa23HLLGDVq1Df6eGbNmhUREeuvv/43ej9Qc5W+jrz77rtx6aWXxmWXXRatW7eu0ccOlK9S15ClS5dGRHzlutG6det48cUXY+XKldX4DJBFiTpz8803lyKi9Oyzz37tMStWrCgtXbr0S699/PHHpc6dO5eOPPLIVa+9/fbbpYgotW7dujRjxoxVr0+aNKkUEaVTTjll1Wv9+/cv9erVq7RkyZJVr61cubLUu3fvUo8ePVa9NmHChFJElCZMmLDaa8OHD/8mH3LpqKOOKjVt2rT0xhtvfKP3A1+2Jqwj+++/f6l3796r/jsiSieccEK13gukNeY1ZM6cOaWqqqrSUUcd9aXXp0yZUoqIUkSU5s6dmzwH+biT0cA0bdo0WrRoERERK1eujHnz5sWKFStiu+22ixdeeGG14wcPHhwbb7zxqv/eYYcdYscdd4zx48dHRMS8efPiscceiwMPPDAWLlwYc+fOjblz58ZHH30UAwYMiKlTp8b777//tfP069cvSqVSnH/++TX+WO6888648cYb49RTT40ePXrU+P3AN1PJ68iECRPinnvuiZEjR9bsgwayqdQ1ZP31148DDzwwbr311rjqqqvirbfeiieeeCKGDBkSzZs3j4jwIJo6pGQ0QLfeemtsvfXW0apVq+jQoUN07NgxHnrooViwYMFqx37VD++bb755TJ8+PSIi3nzzzSiVSnHuuedGx44dv/Rr+PDhERExe/bs7B/DE088EUcddVQMGDAgLrroouznB9IqcR1ZsWJF/PKXv4zDDjsstt9++7LPB3xzlbiGRESMHj069txzzzjttNPi29/+dvz4xz+OXr16xd577x0REWuvvXaW61DM06UamNtvvz2GDh0agwcPjtNPPz06deoUTZs2jUsuuSSmTZtW4/N98XcPTzvttBgwYMBXHtO9e/eyZv53L730Uvz0pz+NrbbaKsaMGRPNmvkyg7pUqevIbbfdFq+//nqMHj161Q8nX1i4cGFMnz49OnXqFGuttVbZ1wK+XqWuIRER7dq1i/vuuy/efffdmD59enTt2jW6du0avXv3jo4dO8a6666b5ToU89NfAzNmzJjo1q1bjB079ktPRvii6f+7qVOnrvbaG2+8EZtuumlERHTr1i0iIpo3bx677bZb/oH/zbRp02LgwIHRqVOnGD9+vD8xgHpQqevIu+++G8uXL48f/ehHq2W33XZb3HbbbTFu3LgYPHhwrc0AVO4a8q822WST2GSTTSIiYv78+fH888/HfvvtVyfX5p/8dakGpmnTphERUSqVVr02adKkr92Q6t577/3S32N85plnYtKkSbHHHntERESnTp2iX79+MXr06Jg5c+Zq758zZ05ynpo8enLWrFnxk5/8JJo0aRKPPPJIdOzYsfA9QH6Vuo4cdNBBMW7cuNV+RUTsueeeMW7cuNhxxx2T5wDKV6lryNc566yzYsWKFXHKKad8o/fzzbiTUQ9uuummePjhh1d7/aSTTopBgwbF2LFjY99994299tor3n777fj9738fPXv2jEWLFq32nu7du0efPn1i2LBhsXTp0hg5cmR06NAhzjjjjFXHXHPNNdGnT5/o1atXHHPMMdGtW7f48MMP4+mnn44ZM2bESy+99LWzPvPMM7HLLrvE8OHDC//B1cCBA+Ott96KM844I5588sl48sknV2WdO3eO3XffvRqfHaA6GuM68p3vfCe+853vfGW22WabuYMBGTXGNSQi4tJLL43JkyfHjjvuGM2aNYt77703/vznP8eFF17o33rVMSWjHlx33XVf+frQoUNj6NChMWvWrBg9enQ88sgj0bNnz7j99tvj7rvvjokTJ672nsMPPzyaNGkSI0eOjNmzZ8cOO+wQo0aNig033HDVMT179oznnnsufvOb38Qtt9wSH330UXTq1Cm22WabrDvpfrFAXH755atlffv2VTIgo8a6jgB1o7GuIb169Ypx48bF/fffH59//nlsvfXW8ac//SkOOOCAbNegeqpK/3ovDAAAoEz+TQYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWVV7M76qqqranAOopkre2sY6Ag1Dpa4j1hBoGKqzhriTAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFk1q+8B+H/69euXzI866qhk/qMf/SiZb7rppjWcaHWvv/56Mr/77ruT+XnnnVf2DAAANGzuZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQVVWpVCpV68CqqtqepdEbNmxYMh85cmQyb9Ysva3JtGnTknmbNm2SeUTEBhtsUHhMOa6//vpkfuKJJybzFStW5BynIlXzW7ZBso5Aw1Cp64g1BBqG6qwh7mQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZJXe3Y0aueyyy5L5SSedlMyXLVuWzHffffdk/uKLLybzVq1aJfOIiHbt2iXzLbbYIpn/5je/SebHHntsMu/SpUsy33fffZN50ecQAIDa504GAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFlVlUqlUrUOrKqq7VkavBYtWiTzmTNnJvN11103md95553J/LDDDkvmDcF2222XzG+44YZk3qtXr2S+//77J/Nx48Yl88agmt+yDZJ1JKJNmzbJ/Fe/+lUyL/oeOfTQQ5P5p59+msyLdO/evfCYli1bJvPp06cn83JnpFilriPWEGgYqrOGuJMBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFb2yaiBPfbYI5k/+OCDZZ1/v/32S+b33ntvWedvCMr9HE6dOjWZf+c736nxTJWmUp9vH2EdiYjo169fMn/00UeT+cKFC5P5j370o2T+6quvJvMiL7/8cuExPXv2TOa77rprMn/88cdrNBM1V6nriDVkzXDwwQcn86K9eG666aac46ym6Ouw6PvrlFNOSeZz584tnOGDDz5I5hMmTCg8RznskwEAANQ5JQMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAsmpW3wNUkjlz5iTzFStWJPPRo0cn8yeffLLGM1Wa//qv/0rmH3/8cTL3jHQq3fbbb1/W+2fMmJHMy90HA1izrbPOOsm8adOmyfyaa65J5m3bti2cYeDAgcm8SZP0n5HX9j4w5Z7/d7/7XdkzjB8/PpnX9j4Z1eFOBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZ2SejBp577rlkvsEGGyTzTz75JJl//vnnNZ6p0vTs2TOZt27dOpnX9rOvobYVfY0DlKNon4vDDjssmf/6179O5p07d67xTLn9+c9/TuY/+clPkvm9996bzN9///1kvt566yXzQw45JJmvKdzJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACAr+2Rk9PHHH9f3CA1e165dk3mrVq3qaBKoH9/97nfrewSgghXtg/GHP/whmR9wwAE5x1nNu+++m8yrsyfY0KFDk/mUKVOSeffu3ZN50c9ru+++ezI/8sgjk3mRJUuWJPNLL7208Bx33313WTPUBXcyAACArJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACArJQMAAMjKPhnUqZYtW9b3CFCvip7PXlVVlcyL9pJp06ZNMv/000+TeQ5FH0P79u1rfYZyrj9v3rw6mgRWd/DBB5eV77XXXjnHWc2jjz6azPfbb79kvmjRorJnaN68eTLfbbfdknnRPhybbbZZTUeqkRdeeCGZX3DBBbV6/briTgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWdkngzp16qmnlvX+W265Jc8gUE/uuuuuZH700Ucn827duiXzAw88MJnffPPNyTyHUqmUzIcMGZLMx40bV9b1TzvttGR+zDHHJPOzzz47md9zzz01ngm+ULRPy/HHH5/Me/funXOc1QwaNCiZT5o0KZlvuummybxFixaFM2y//fbJ/OSTT07mm2++eeE1atMHH3yQzIvmbyzcyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgK/tkkNWhhx6azPv06ZPMp06dmsyvueaaGs8EDcny5cuT+eeff57MmzVLL9unnHJKMt9kk02S+SOPPFLW9aujZ8+eyXz48OHJfKONNkrmQ4cOTeZFH8MBBxyQzO2TQTn22GOPZF7b+2AU2X///ZP5rrvumsz/4z/+I5mvtdZaNZ6pofnwww+TedHn8Pnnn885ToPlTgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWVWVSqVStQ6sqqrtWRq9Vq1aJfPvfe97tXr9d955p/CYWbNmJfOiZ+z/+c9/Tuabb755Mn/ooYeS+d57753M1wTV/JZtkKwjxV5++eVkXrTHREP4+ij6/1zfMy5evDiZH3744cl83LhxOcepF/X9/+CbagxryM9//vNkftttt9XRJHxTr776ajLv1atXHU1Sf6qzhriTAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJBVs/oeoCHZeOONk/kxxxyTzPfbb79k3qZNm2TetWvXZF6kaJOi2bNnF55jwYIFyXzddddN5uuvv34y//TTT5P5ZZddlsyhsRs8eHAy/+1vf5vMhwwZknGayvTHP/4xmY8ZMyaZ33fffTnHgS/529/+lsyLNuSs9I3ebr755sJjijbMPP7443ON843ccMMN9Xr9SuFOBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZVZVKpVK1DizYg6EhaNq0aTI/99xzk/kvf/nLZF60R8SiRYuS+dKlS5P5ww8/nMw/+uijZF7koIMOKjymY8eOZV2jyJlnnpnMr7jiilq9fmNQzW/ZBqkS1pFKV7TPxoYbbljW+avzfPqtttoqmT///PPJfOedd07mRc/Qp1ilriNrwhrSvHnzZD5w4MBkfvjhh5d1/enTpyfzc845p6zzr1ixovCYCy+8MJmfccYZZc2wZMmSZH7iiScm81tvvTWZr1y5ssYzVZrqrCHuZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQVaPaJ+Oiiy5K5kV7NBQp2sPhuuuuS+bvvPNOWdcv15AhQwqPufPOO2t1hqK9QPbaa69avX5jUKnPt4+ojHWEtGHDhhUeM2rUqGR+9913J/Pq7OlDeSp1HbGGNHxFe5adcMIJhee46qqrknmTJuX9Gfm7776bzDfbbLOyzr8msE8GAABQ55QMAAAgKyUDAADISskAAACyUjIAAICslAwAACArJQMAAMiqWX0PkNMBBxyQzD/99NNkvsceeyTzp556qsYz1aWi+c8///zCcxQ9g/yRRx5J5htssEEy33PPPZP5sccem8z/8Ic/JHMAoP6cd955yfycc86p9Rlef/31ZP6zn/2s1mfAnQwAACAzJQMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAsmpU+2Q8/PDDyfyoo45K5kV7RNS3gQMHJvOxY8cm8xYtWhRe45VXXknmxx13XDLv379/Mr/xxhuT+fDhw5P5uHHjkvmcOXOSOQDw9Zo3b57M119//WRe9HNCDsuWLUvmRftgTJkyJec4fA13MgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADIqlHtk/G73/0umR944IHJ/MEHH0zm9957bzIfM2ZMMv/ggw+S+WmnnZbM995772TesmXLZP7QQw8l84iIE088MZm/++67ybzoc3DSSScl8169eiXzQw89NJmPGDEimQP179vf/nYyb926dTJfvHhxznGAf3HmmWcm8/PPP7/WZ3jjjTeSedG+YPbBaBjcyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgq0a1T8b06dOTeZ8+fZL55MmTk/nhhx+ezA877LBkXq6lS5cm89GjRyfz6jzb+sMPP6zJSKtZuHBhMr/nnnuSedE+Geuss06NZwLyadKk+M+mio75wQ9+kMy7dOmSzIueoQ98vY4dOybzI444oo4m+Xr77LNPMrcGVAZ3MgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADIqlHtk1HkzTffTOZF+2icdNJJybxUKtV4pn9V9Nzn+++/P5n/4x//KOv6deG5556r7xGAMtx7772Fx1x99dXJvGitPOigg5L5b3/728IZYE113HHHJfMhQ4Yk88022yznOKsZN25c4TFvvfVWrc5A3XAnAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICsqkrV3NyhqqqqtmcBqqHc/Vjqk3VkzfD5558n86Kv4csvvzyZn3322TWeiS+r1HXEGlLsqaeeSuY77bRTrV5/xx13TOZTpkwpPMeiRYtyjUMtqc4a4k4GAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFY244MKU6mbaEVYR9YU7733XjLfcMMNk/mcOXPKej/FKnUdsYYUq+/N+DbeeONkPmvWrFq9PnXDZnwAAECdUzIAAICslAwAACArJQMAAMhKyQAAALJSMgAAgKyUDAAAIKtm9T0AAI3LaaedlsyvuOKKZP6b3/wm5zhAHRo2bFgyHz58eB1NQn1zJwMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArKpKpVKpWgdWVdX2LEA1VPNbtkGyjkDDUKnriDWk2FNPPZXMd9ppp7LOf8cddyTz4447LpkvXry4rOvTMFRnDXEnAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICs7JMBFaZSn28fYR2BhqJS1xFrCDQM9skAAADqnJIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFlVe58MAACA6nAnAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACArJQMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACArJQMAAMhKyQAAALJSMgAAgKyUjAo1ffr0qKqqiiuvvDLbOSdOnBhVVVUxceLEbOcEGi7rCFAOawgpSkYduuWWW6Kqqiqee+65+h6lVpx//vlRVVW12q9WrVrV92jQaDT2deT111+PU045JXr37h2tWrWKqqqqmD59en2PBY1GY19Dxo0bFwMGDIiNNtooWrZsGd/61rdi//33j8mTJ9f3aGucZvU9AI3PddddF2uvvfaq/27atGk9TgNUkqeffjquvvrq6NmzZ2y55Zbx97//vb5HAirIyy+/HOutt16cdNJJsf7668esWbPipptuih122CGefvrp+N73vlffI64xlAyy23///WP99dev7zGACvTTn/405s+fH23bto0rr7xSyQBq5LzzzlvttaOPPjq+9a1vxXXXXRe///3v62GqNZO/LtXALFu2LM4777zYdttto127dtGmTZvYeeedY8KECV/7nhEjRkTXrl2jdevW0bdv36+8JThlypTYf//9o3379tGqVavYbrvt4v777y+c57PPPospU6bE3Llzq/0xlEql+OSTT6JUKlX7PUA+lbyOtG/fPtq2bVt4HFB7KnkN+SqdOnWKtdZaK+bPn/+N3s83o2Q0MJ988knccMMN0a9fv7jsssvi/PPPjzlz5sSAAQO+8k/0brvttrj66qvjhBNOiLPOOismT54cu+66a3z44YerjnnllVdip512itdeey3OPPPMuOqqq6JNmzYxePDgGDduXHKeZ555JrbccssYNWpUtT+Gbt26Rbt27aJt27Zx6KGHfmkWoPY1hnUEqD+NYQ2ZP39+zJkzJ15++eU4+uij45NPPon+/ftX+/1kUKLO3HzzzaWIKD377LNfe8yKFStKS5cu/dJrH3/8calz586lI488ctVrb7/9dikiSq1bty7NmDFj1euTJk0qRUTplFNOWfVa//79S7169SotWbJk1WsrV64s9e7du9SjR49Vr02YMKEUEaUJEyas9trw4cMLP76RI0eWTjzxxNIdd9xRGjNmTOmkk04qNWvWrNSjR4/SggULCt8PFGvs68i/uuKKK0oRUXr77bdr9D7g660pa8gWW2xRiohSRJTWXnvt0jnnnFP6/PPPq/1+yudORgPTtGnTaNGiRURErFy5MubNmxcrVqyI7bbbLl544YXVjh88eHBsvPHGq/57hx12iB133DHGjx8fERHz5s2Lxx57LA488MBYuHBhzJ07N+bOnRsfffRRDBgwIKZOnRrvv//+187Tr1+/KJVKcf755xfOftJJJ8V//ud/xiGHHBL77bdfjBw5Mm699daYOnVqXHvttTX8TADfVCWvI0D9awxryM033xwPP/xwXHvttbHlllvG4sWL4/PPP6/2+ymfktEA3XrrrbH11ltHq1atokOHDtGxY8d46KGHYsGCBasd26NHj9Ve23zzzVc98vHNN9+MUqkU5557bnTs2PFLv4YPHx4REbNnz661j+WQQw6JDTbYIB599NFauwawusa0jgB1r9LXkB/+8IcxYMCAGDZsWDzyyCNx++23x1lnnZX1GqR5ulQDc/vtt8fQoUNj8ODBcfrpp0enTp2iadOmcckll8S0adNqfL6VK1dGRMRpp50WAwYM+MpjunfvXtbMRbp06RLz5s2r1WsA/09jXEeAutPY1pD11lsvdt1117jjjjuybhxImpLRwIwZMya6desWY8eOjaqqqlWvf9H0/93UqVNXe+2NN96ITTfdNCL++Y+wIyKaN28eu+22W/6BC5RKpZg+fXpss802dX5tWFM1tnUEqFuNcQ1ZvHjxV96Fofb461INzBcb15X+5fGvkyZNiqeffvorj7/33nu/9PcYn3nmmZg0aVLsscceEfHPx7b169cvRo8eHTNnzlzt/XPmzEnOU5PHxn3Vua677rqYM2dODBw4sPD9QB6VvI4A9a+S15Cv+mtX06dPj7/85S+x3XbbFb6ffNzJqAc33XRTPPzww6u9ftJJJ8WgQYNi7Nixse+++8Zee+0Vb7/9dvz+97+Pnj17xqJFi1Z7T/fu3aNPnz4xbNiwWLp0aYwcOTI6dOgQZ5xxxqpjrrnmmujTp0/06tUrjjnmmOjWrVt8+OGH8fTTT8eMGTPipZde+tpZn3nmmdhll11i+PDhhf/gqmvXrjFkyJDo1atXtGrVKp588sm466674vvf/34cd9xx1f8EAYUa6zqyYMGC+M///M+IiHjqqaciImLUqFGx7rrrxrrrrhsnnnhidT49QIHGuob06tUr+vfvH9///vdjvfXWi6lTp8aNN94Yy5cvj0svvbT6nyDKV1+PtVoTffHYuK/79d5775VWrlxZuvjii0tdu3YttWzZsrTNNtuUHnzwwdIRRxxR6tq166pzffHYuCuuuKJ01VVXlbp06VJq2bJlaeeddy699NJLq1172rRppcMPP7y0wQYblJo3b17aeOONS4MGDSqNGTNm1THlPjbu6KOPLvXs2bPUtm3bUvPmzUvdu3cv/epXvyp98skn5XzagH/R2NeRL2b6ql//OjvwzTT2NWT48OGl7bbbrrTeeuuVmjVrVtpoo41KBx10UOkf//hHOZ82voGqUsm2zAAAQD7+TQYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWVV7x++qqqranAOopkre2sY6Ag1Dpa4j1hBoGKqzhriTAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZNavvAQDgX7Vs2TKZ//GPf0zm++yzTzIfNGhQMv+v//qvZA5AMXcyAACArJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACArJQMAAMhKyQAAALKyGR8Adapdu3bJfOTIkcn8pz/9aTIvlUo1HQkqxkYbbVTW+z/44INMk0CaOxkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZGWfDADq1A477JDMDzvssDqaBGqmOntUDBgwIJnvuuuuyfy73/1uMt9ggw2S+bRp05L5hx9+mMzffvvtZP7CCy8k88cffzyZ26djzeFOBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZ2SeDNUrRM85/8IMfFJ6jV69eyfzFF19M5g8//HDhNaAxu+KKK+p7BPhK++23XzK/6qqrCs/RpUuXsmaoqqpK5qVSKZl37ty5Xq8/Z86cZD5z5szCGWbNmpXMhw0blszff//9ZL58+fLCGSifOxkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZGWfDLLacMMNk3nR87v79u2bzL/3ve8l87333juZt2jRIpmvvfbayTwiYtmyZcl8zJgxydw+GTR2l156aTLfYostavX6f/nLX5L5xIkTa/X6VK7jjjsumVdnD4wHH3wwmRftpbTZZpsl86J9Kop069Ytmffp06es83fs2LGsPKL49/pp06Yl82uuuSaZ//KXvyycgfK5kwEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVlWlaj5wuaqqqrZnocBWW22VzHffffdkPnjw4MJrrLPOOjUZaTUbbLBBMu/UqVNZ569tDz30UOExzz77bDK/4IILco3zlcp9Rnp9so6sGT7//PNkXu7X8IIFC5L5QQcdlMz/+7//u6zrNwaVuo5YQ+rfeuutl8xPP/30ZD5o0KDCaxT9vFOuoUOHJvPbbrutVq/fGFRnDXEnAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICs7JPRgJx88snJ/Fe/+lUyr4s9KIq+Dur72etvvPFGMr/vvvuS+a9//evCaxTtAVDb6vtzXA7rSOWrzn4799xzTzIv92v4kksuSebnnntuWedfE1TqOmINqXytW7cuPGbgwIHJfMSIEcm8S5cuyXzJkiXJ/Mc//nEyf/7555P5msA+GQAAQJ1TMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgq2b1PcCa5Nhjj03mV1xxRTJv0qT+O+HTTz+dzFeuXJnMH3nkkWQ+Z86cZP5//s//SeaffvppMl++fHkyhzXduuuum8yHDRtW6zMsW7Ysmb/88su1PgNQOxYvXlx4zLhx45L5pptumsyvvPLKZN6qVatk3rNnz2Run4zqqf+fWgEAgEZFyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArOyTUYe22WabZF60D8bjjz+ezP/jP/4jmRftYVEdb775ZtnnABquESNGJPP+/fvX+gxF68yf/vSnWp8BKtWgQYOS+XrrrZfMN9poo2T+/e9/P5mPHz8+mVfHoYcemsx//OMfl32NlLfeeqtWz7+mcCcDAADISskAAACyUjIAAICslAwAACArJQMAAMhKyQAAALJSMgAAgKzsk1GHivbJKNK3b99kfsEFFyTz6jy7etq0acncPhnQuHXr1q3Wr1G0jvzsZz+r9RmgUm2yySbJ/NZbb03mRftklGvIkCG1ev4chg0blsyfeuqpOpqkcXMnAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICs7JNRh4qeu7zDDjuUdf4DDjigrLw6qqqqkvnZZ5+dzK+99tpkvmDBghrPBFTfddddl8z79OlT9jWaNEn/+dXdd9+dzO3HA19v5syZyfyDDz5I5uuuu24yL/p9vlQqJfMcanuGiy66KJnPnj07mT/44IPJfPny5TWeqTFyJwMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgq6pSNXc0KdoYpRJssMEGybxog5opU6aUdf2i8w8dOjSZH3fcccm8VatWyXyTTTZJ5tVR7gY5J554YjIv2iiMutkIqbY0hnWkoTv55JOT+WWXXZbMmzZtWvYMRZuF9e3bN5m/9dZbZc9AWqWuI9aQYoMHD07mP/zhD5N5ub/P9+zZM5lvu+22yTwi4v3330/mPXr0SOZFa9C3vvWtZN6mTZtk/otf/CKZX3PNNcm8MajOGuJOBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZNavvAerSSy+9lMwPO+ywZF7uPhnz589P5iNHjiwrb9u2bTL/7ne/m8yr4+CDD07mRftgbLXVVmXPAGuyJk3SfzbUpUuXZJ5jH4wi++67bzK3DwZ8vaL9oor23Dr++OOT+b333lvDiepehw4dkvnaa6+dzDfccMNkfvbZZyfzQYMGJfPTTjstmf/tb39L5s8//3wybyzcyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgq6pSqVSq1oFVVbU9S61buXJlMv/kk0+S+dVXX53Mi55tPXPmzGTeEOy0007J/M4770zmXbt2TebnnHNOMr/kkkuSORHV/JZtkBrDOlLfNtlkk2TeEPagaNZsjdqCqSJV6jqyJqwht912WzI/9NBDk/nll1+ezG+//fZkPnny5GTeGHTr1i2ZP/HEE8m8aB+OIkOHDk3mRV8DDUF11hB3MgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADIao3aJ+Phhx9O5rvvvntZ51+0aFEyf+qpp5L5a6+9Vtb1i/Tq1avwmB//+MfJvEWLFsn8mmuuSeannHJKMl+xYkUyp3Kfbx/RONaR2ta5c+dkfssttyTzctexov2CTjjhhMJz/PGPfyxrBmpfpa4ja8Ia8v3vfz+ZX3zxxcl8wIAByXzJkiXJvGg/q1GjRiXz5cuXJ/NKcPLJJyfzq666qqzz/+///b+TedE+Gg2BfTIAAIA6p2QAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZr1D4Z3bt3T+bXX399Mi/aQ2JN8MorryTzos/R/PnzM06zZqrU59tHNI51pLbttddeyfy+++6r1esff/zxyfwPf/hDrV6fulGp64g1JKJnz57J/LHHHkvmHTt2TOZFn+OiPR7OPffcZP7uu+8m84agbdu2yfyBBx5I5jvvvHMyL9o3rRJ+3rRPBgAAUOeUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADIqll9D1CX3nzzzWS+9957J/O+ffsm86LnGnft2jWZ17ZPP/208JixY8cm84ceeijXOEADVLQXDlC/Xn311WT+f//v/03m++yzT1nXP/TQQ5N5nz59kvmf//znwmvcc889yfzRRx8tPEc5Fi5cmMzXWWedss7/1ltvlfX+SuFOBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZVZVKpVK1Dqyqqu1ZgGqo5rdsg2QdKfbaa68l8x49epR1/unTpyfzPffcM5m/8cYbZV2fhqFS1xFrSPl22223svKf//znyXzjjTeu8Uz/ruj/87x585L5gw8+WNb1N9poo2Tev3//ZL506dJkPnz48GR++eWXJ/OGoDpriDsZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGRlnwyoMJX6fPsI60h1vP3228m8S5cuZZ3/yiuvTOZnnnlmWeenMlTqOmINqX0tW7ZM5q1atUrmvXv3TubXXntt4Qxdu3ZN5rX99Vv0dfbpp58m83fffTeZF+1FMnPmzGTeENgnAwAAqHNKBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkZZ8MqDCV+nz7COtIdVxyySXJ/PTTTy/r/O3bt0/mn3zySVnnpzJU6jpiDal82267beExJ598cjLv379/Mm/SJP1n6G3atEnmhx12WDJ/9dVXk/mcOXOS+ccff5zMK4F9MgAAgDqnZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlc34oMJU6iZaEdYRaCgqdR2xhlAdLVu2TOY9evRI5pMnT845TqNkMz4AAKDOKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJV9MqDCVOrz7SOsI9BQVOo6Yg2BhsE+GQAAQJ1TMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACArJQMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACCrqlKpVKrvIQAAgMbDnQwAACArJQMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACArJQMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIq1PTp06OqqiquvPLKbOecOHFiVFVVxcSJE7OdE2i4rCNAOawhpCgZdeiWW26JqqqqeO655+p7lFrz/vvvx4EHHhjrrrturLPOOrHPPvvEW2+9Vd9jQaPR2NeRsWPHxpAhQ6Jbt26x1lprxRZbbBGnnnpqzJ8/v75Hg0ahsa8hm266aVRVVX3lrx49etT3eGuUZvU9AI3HokWLYpdddokFCxbE2WefHc2bN48RI0ZE37594+9//3t06NChvkcEGrhjjz02Ntpoozj00ENjk002iZdffjlGjRoV48ePjxdeeCFat25d3yMCDdjIkSNj0aJFX3rtnXfeiXPOOSd+8pOf1NNUayYlg2yuvfbamDp1ajzzzDOx/fbbR0TEHnvsEVtttVVcddVVcfHFF9fzhEBDN2bMmOjXr9+XXtt2223jiCOOiDvuuCOOPvro+hkMqAiDBw9e7bULL7wwIiJ+/vOf1/E0azZ/XaqBWbZsWZx33nmx7bbbRrt27aJNmzax8847x4QJE772PSNGjIiuXbtG69ato2/fvjF58uTVjpkyZUrsv//+0b59+2jVqlVst912cf/99xfO89lnn8WUKVNi7ty5hceOGTMmtt9++1UFIyLiO9/5TvTv3z/+9Kc/Fb4fyKOS15F/LxgREfvuu29ERLz22muF7wfKV8lryFe58847Y7PNNovevXt/o/fzzSgZDcwnn3wSN9xwQ/Tr1y8uu+yyOP/882POnDkxYMCA+Pvf/77a8bfddltcffXVccIJJ8RZZ50VkydPjl133TU+/PDDVce88sorsdNOO8Vrr70WZ555Zlx11VXRpk2bGDx4cIwbNy45zzPPPBNbbrlljBo1KnncypUr4x//+Edst912q2U77LBDTJs2LRYuXFi9TwJQlkpdR77OrFmzIiJi/fXX/0bvB2qmMa0hL774Yrz22mtxyCGH1Pi9lKlEnbn55ptLEVF69tlnv/aYFStWlJYuXfql1z7++ONS586dS0ceeeSq195+++1SRJRat25dmjFjxqrXJ02aVIqI0imnnLLqtf79+5d69epVWrJkyarXVq5cWerdu3epR48eq16bMGFCKSJKEyZMWO214cOHJz+2OXPmlCKi9Nvf/na17JprrilFRGnKlCnJcwDFGvM68nWOOuqoUtOmTUtvvPHGN3o/8P+saWvIqaeeWoqI0quvvlrj91IedzIamKZNm0aLFi0i4p93B+bNmxcrVqyI7bbbLl544YXVjh88eHBsvPHGq/57hx12iB133DHGjx8fERHz5s2Lxx57LA488MBYuHBhzJ07N+bOnRsfffRRDBgwIKZOnRrvv//+187Tr1+/KJVKcf755yfnXrx4cUREtGzZcrWsVatWXzoGqF2Vuo58lTvvvDNuvPHGOPXUUz0ZBupIY1lDVq5cGXfddVdss802seWWW9bovZRPyWiAbr311th6662jVatW0aFDh+jYsWM89NBDsWDBgtWO/arfdDfffPOYPn16RES8+eabUSqV4txzz42OHTt+6dfw4cMjImL27Nllz/zFE1+WLl26WrZkyZIvHQPUvkpcR/7dE088EUcddVQMGDAgLrroouznB75eY1hDHn/88Xj//ff9g+964ulSDcztt98eQ4cOjcGDB8fpp58enTp1iqZNm8Yll1wS06ZNq/H5Vq5cGRERp512WgwYMOArj+nevXtZM0dEtG/fPlq2bBkzZ85cLfvitY022qjs6wDFKnUd+VcvvfRS/PSnP42tttoqxowZE82a+e0K6kpjWEMiIu64445o0qRJHHzwwdnPTTGrdgMzZsyY6NatW4wdOzaqqqpWvf5F0/93U6dOXe21N954IzbddNOIiOjWrVtERDRv3jx22223/AP//5o0aRK9evX6ys19Jk2aFN26dYu2bdvW2vWB/6dS15EvTJs2LQYOHBidOnWK8ePHx9prr13r1wT+n0pfQyL++Tcr7rnnnujXr58/5Kwn/rpUA9O0adOIiCiVSqtemzRpUjz99NNfefy99977pb/H+Mwzz8SkSZNijz32iIiITp06Rb9+/WL06NFfeZdhzpw5yXlq8ti4/fffP5599tkvFY3XX389HnvssTjggAMK3w/kUcnryKxZs+InP/lJNGnSJB555JHo2LFj4XuAvCp5DfnC+PHjY/78+f6qVD1yJ6Me3HTTTfHwww+v9vpJJ50UgwYNirFjx8a+++4be+21V7z99tvx+9//Pnr27LnaDpYR/7y92KdPnxg2bFgsXbo0Ro4cGR06dIgzzjhj1THXXHNN9OnTJ3r16hXHHHNMdOvWLT788MN4+umnY8aMGfHSSy997azPPPNM7LLLLjF8+PDCf3B1/PHHx/XXXx977bVXnHbaadG8efP43e9+F507d45TTz21+p8goFBjXUcGDhwYb731Vpxxxhnx5JNPxpNPPrkq69y5c+y+++7V+OwARRrrGvKFO+64I1q2bBn77bdftY4nPyWjHlx33XVf+frQoUNj6NChMWvWrBg9enQ88sgj0bNnz7j99tvj7rvvjokTJ672nsMPPzyaNGkSI0eOjNmzZ8cOO+wQo0aNig033HDVMT179oznnnsufvOb38Qtt9wSH330UXTq1Cm22WabOO+887J9XG3bto2JEyfGKaecEhdeeGGsXLky+vXrFyNGjPCnkZBZY11HvvhB4/LLL18t69u3r5IBmTTWNSTin/t8PPTQQ7HXXntFu3btsp6b6qsq/eu9MAAAgDL5NxkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZFXtzfiqqqpqcw6gmip5axvrCDQMlbqOWEOgYajOGuJOBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGTVrL4HAKBydO7cufCYFi1aJPNzzz03mR911FE1mqmmmjRJ//naAw88kMzHjBmTzG+77bYazwTQ2LiTAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWVaVSqVStA6uqanuWNV6fPn2S+cSJE5N506ZNk/kbb7xROMPFF1+czG+99dbCc1C7qvkt2yBZR+pfy5Ytk/k555yTzI877rjCa7Rv3z6ZF30d1PbXeLnXnzBhQjIfNGhQ4QxLly4tPKY2Veo6Yg2BhqE6a4g7GQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZ2YyvDu2yyy7J/P7770/ma621Vs5xvtKKFSuS+UEHHZTMx40bl3McvkKlbqIVYR1pCNZdd91k/vTTTyfzHj16lD1D0dfB3Llzk3nRZnhFitbSPffcs6zz/+xnPys8pmi9r22Vuo5YQ6BhsBkfAABQ55QMAAAgKyUDAADISskAAACyUjIAAICslAwAACArJQMAAMjKPhkZbbLJJsn8xRdfTOZFz68v11//+tfCY4r+P3/7299O5rfccksyP/fccwtnIK1Sn28fYR1pCLp06ZLM33777bKv8cILLyTz8ePHJ/Nrr702mc+ePbvGM/2r2v4cbLrppoXHzJgxo6xrlKtS1xFrCDQM9skAAADqnJIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFk1q+8BGpPPP/88mS9btqyOJvlqJ598cuEx06ZNS+Zjx45N5qeeemoyt08G1K/33nsvmQ8ePDiZ9+jRo/AaN9xwQzJfuHBh4Tlq0w9+8INk/uabbybzzz77LJkX7ScUUf/7ZFB/3nnnnWRe9LNC3759k/msWbOSedu2bZN5kybpP3/u0KFDMm/atGkyz2HDDTdM5suXL0/mm2++eTIvWiN+/vOfJ/Mnnngime+zzz7JvLFwJwMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArKpKpVKpWgdWVdX2LI3eddddl8yPPfbYss6/aNGiZL7jjjsWnmPKlCnJfODAgcn8gQceSOb33XdfMj/ssMOS+eLFi5P5mqCa37INknWEhqBonevevXsyHzNmTDI/6KCDajxTXavUdaQxrCFFe1aNGDEimc+ePTuZT548OZl36tQpmTdv3jyZd+vWraz3rwmmT5+ezDfbbLO6GaQWVWcNcScDAADISskAAACyUjIAAICslAwAACArJQMAAMhKyQAAALJSMgAAgKya1fcAjUnHjh2TeZ8+fWr1+vfff38yL3o2fHU8+eSTyfzxxx9P5vvuu28yP/DAA5P5rbfemswBzjvvvGTeo0ePZF70/Pe77rqrxjPBF/7X//pfyfyJJ55I5occckgyL9qnYuedd07m5Vq+fHnZ5xg9enQyX7ZsWVnnf/DBB5P5Y489Vtb5b7rpprLe31i4kwEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVvbJyGidddZJ5j179qyjSWrPokWLkvnkyZOT+S677JLMd9xxx2Runwxg0KBByfzXv/51WeefOXNmMn/xxRfLOj9rtqJ9WJ5//vmy8iK//OUvy3p/JVhvvfWS+QcffFDW+Yv2MrnooovKOn9j4U4GAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFnZJ4Oszj777GT+i1/8Ipn36tUrmbdr1y6ZL1iwIJkD9a9Lly7J/LLLLkvmQ4YMKev6n3zySTLv379/Mn/nnXfKuj5QnvXXXz+Zjxs3Lpm3atUqmU+aNCmZn3HGGcl85cqVyXxN4U4GAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFnZJyOjbbbZpl6vf9FFF9Xr9SMiPv/887Le37t372TeoUOHZG6fDKh/2267bTK/4447knn37t2TealUqvFM/+qDDz4o6/1A7aqqqkrmRxxxRDLv06dPMn/vvfeS+S677JLMFy9enMz5J3cyAACArJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACArJQMAAMjKPhkZHXTQQfV6/YULF9br9etCjx49kvlbb71VR5NAZVprrbWS+V577ZXMhwwZUniNPffcM5m3bNkymZe7D8Yf//jHZH7GGWck85kzZ5Z1faA8RT9PXXnllWWd/2c/+1kytw9GHu5kAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVfTIqyJw5c5L58uXLa32GFi1aJPOzzjqrVq+/xx57JPNHHnmkVq8PDd22226bzPfee+9kfs455+Qcp1YU7YNx9913J3P7YED92X333QuPueCCC8q6xsiRI5P5iy++WNb5qR53MgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyshlfRgsWLKjV8z/wwAPJ/KOPPqrV60dEdOrUKZmfe+65ZZ3/b3/7WzI///zzyzo/NHQdOnRI5kceeWQyL9pMr23btsm8VCol8xz+8Ic/JPNhw4bV+gxA7ejWrVsyv+mmmwrP8a1vfSuZ//Wvf03mp59+ejL//PPPC2egfO5kAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVfTIymjx5cq2e/4gjjkjmw4cPT+YffPBB2TM0a1a7XzI77bRTMm/fvn0ynz9/fsZpoOY22mijZH744Ycn86I9IjbeeOMaz/SvivbBWLhwYTIfO3Zs4TXGjx+fzMeMGVN4DqBhatOmTTL/y1/+ksyL9sCIiJg6dWoyL1pHV6xYUXgNap87GQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkZZ+MjH70ox/V6vmvueaaZJ5jH4wiF110Ua1fAxqyLl26JPOHHnoomX/3u99N5kX7WNS3LbbYouxj/uf//J/JvNzPwQ033JDMb7755rLOD2uyCy+8MJlvuummZV/j17/+dTJ/5513yr4Gtc+dDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADISskAAACysk9GDXTu3DmZb7bZZnU0Se057rjjkvn+++9fr9efPn16rV4fjjnmmGRetFdM+/btc45T59Zee+1kvuOOO5Z9jaqqqmRe7j4ZRTM2a5b+re/6669P5ttuu20yf/7555M5NGT77rtvMj/ppJPKOv/o0aMLj3nggQfKugYNgzsZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGRln4waaNeuXTLv1KlTHU3yzfTp06fwmCuvvDKZFz1fvsiUKVOS+R133JHMV65cWdb1WbN16dKl8JhTTz01mXfo0KGsGYr2iKht9X39HDN89tlnyXzevHnJ/IUXXijr+vbBoJIV7YVz2GGHJfOi799FixYl85EjRybziIglS5YUHkPD504GAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVkgEAAGSlZAAAAFnZJ6MG3njjjWQ+adKkZL7vvvuWdf0hQ4Yk85122imZF+3zERGx1lprJfOlS5cm86eeeiqZ/4//8T+S+eLFi5M5lOPkk08uPKZ79+7JvFQqZZqmds4/c+bMZL58+fJk/v777yfzqVOnFs4wfvz4wmPKMWPGjGT+t7/9rVavD5XsvPPOS+ZFP6ssW7YsmR9yyCHJvGi/LBoPdzIAAICslAwAACArJQMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyMo+GRndfPPNybzcfTI6d+5cVp7DK6+8ksx33333Wp8BvqkXXnihvkeIl156KZkX7cdTlN94443JvOgZ90X7bAANW4sWLZL5wIEDyzr/7Nmzk/kDDzxQ1vlpPNzJAAAAslIyAACArJQMAAAgKyUDAADISskAAACyUjIAAICslAwAACAr+2Rk9Ne//jWZP/TQQ8l8r732yjnON/Lqq68m8yFDhtTRJJDf888/X/Y5ivapuOCCC5L5gw8+mMwXLlxY45kAvnDCCSck8169epV1/qI1Dr7gTgYAAJCVkgEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWVWVSqVStQ6sqqrtWRq9li1bJvNf/OIXyfziiy9O5k2bNq3xTP9uwIAByfzRRx8t+xqUp5rfsg2SdQQahkpdR6whEd26dUvmL7zwQjJv165dMn/44YeT+d57753MV6xYkcxpHKqzhriTAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZKRkAAEBWSgYAAJCVzfigwlTqJloR1hFoKCp1HbGGRIwYMSKZn3zyycl8xowZybx3797J/L333kvmrBlsxgcAANQ5JQMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAsmpW3wMAAPBPbdu2Tea77rprWeefM2dOMrcPBrm4kwEAAGSlZAAAAFkpGQAAQFZKBgAAkJWSAQAAZKVkAAAAWSkZAABAVvbJAABoINZee+1kPmPGjGS+9dZbJ/N//OMfNZ4Jvgl3MgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADIqqpUKpWqdWBVVW3PAlRDNb9lGyTrCDQMlbqOWEOgYajOGuJOBgAAkJWSAQAAZKVkAAAAWSkZAABAVkoGAACQlZIBAABkpWQAAABZVXufDAAAgOpwJwMAAMhKyQAAALJSMgAAgKyUDAAAICslAwAAyErJAAAAslIyAACArJQMAAAgKyUDAADI6v8DAj1AbTCT0JIAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## 2. Implementing the Linear Layer\n","\n","The **Linear** (or fully connected / dense) layer is one of the fundamental building blocks of neural networks.  \n","It performs a **linear transformation** of the input:\n","\n","$$\n","Z = XW + b\n","$$\n","\n","- **Forward pass:**  \n","  Takes the input $X \\in \\mathbb{R}^{\\text{batch} \\times n_{\\text{in}}}$ and computes the weighted sum using the weight matrix $W \\in \\mathbb{R}^{n_{\\text{in}} \\times n_{\\text{out}}}$ and bias vector $b \\in \\mathbb{R}^{n_{\\text{out}}}$.\n","- **Backward pass:**  \n","  Computes the gradients of the loss with respect to $W$, $b$, and $X$ so we can update the parameters during training.\n","- **Update step:**  \n","  Applies a gradient descent step to $W$ and $b$ using the computed gradients and a learning rate.\n","\n","Below is a template where you will fill in the missing pieces (`# TODO`) to implement forward, backward, and update logic."],"metadata":{"id":"DwO8LEOd_CM5"}},{"cell_type":"code","source":["class Linear:\n","    \"\"\"\n","    A simple fully connected (dense) layer.\n","    Performs a linear transformation:  Z = XW + b\n","    \"\"\"\n","\n","    def __init__(self, nin, nout, device=\"cpu\"):\n","        \"\"\"\n","        Initialize the layer parameters.\n","        \"\"\"\n","        # Initialize weights from a normal distribution\n","        self.W = torch.randn(nin, nout, device=device, requires_grad=False)\n","        # Initialize biases to zero\n","        self.b = torch.zeros(nout, device=device, requires_grad=False)\n","        self.training = True  # for compatibility with Dropout/BatchNorm\n","\n","    def train(self):\n","        \"\"\"Switch to training mode.\"\"\"\n","        self.training = True\n","        return self\n","\n","    def eval(self):\n","        \"\"\"Switch to evaluation mode.\"\"\"\n","        self.training = False\n","        return self\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Forward pass: compute the output of the layer.\n","        \"\"\"\n","        self.X = X  # store for backward pass\n","        # TODO: Implement Z = XW + b\n","        pass\n","\n","    def backward(self, dZ):\n","        \"\"\"\n","        Backward pass: compute gradients w.r.t. W, b, and X.\n","        \"\"\"\n","        # TODO: Compute self.dW, self.db, and self.dX\n","        pass\n","\n","    def update(self, lr):\n","        \"\"\"\n","        Update parameters using gradient descent.\n","        \"\"\"\n","        # TODO: Update W and b using self.dW and self.db\n","        pass\n","\n","# Example usage\n","nin = 4\n","nout = 3\n","n_batch = 5\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# Simulated input tensor\n","X = torch.randn(n_batch, nin).to(device)\n","\n","# Create an instance of the Linear class and compute the linear transformation\n","net = Linear(nin, nout, device=device)\n","Z = net.forward(X)\n","print(Z.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A20c5lPy8dCQ","executionInfo":{"status":"ok","timestamp":1755028362796,"user_tz":300,"elapsed":55,"user":{"displayName":"Juan David Martinez Vargas","userId":"15315348669826032119"}},"outputId":"9bddd4f9-679c-483f-b526-14fa628a2035"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 3])\n"]}]},{"cell_type":"markdown","source":["## 3. CrossEntropyFromLogits Loss\n","\n","To train a neural network for **classification**, we need a loss function that measures how well the predicted class scores (logits) match the true labels.  \n","A very common choice is the **Cross-Entropy Loss**, combined with the **Softmax** function.\n","\n","### Step 1: Softmax\n","\n","Given the logits for each sample:\n","$$\n","Z \\in \\mathbb{R}^{m \\times C}\n","$$\n","where $m$ is the batch size and $C$ is the number of classes,  \n","the softmax function converts logits into probabilities:\n","\n","$$\n","A_{i,j} = \\frac{\\exp(Z_{i,j})}{\\sum_{k=1}^{C} \\exp(Z_{i,k})}\n","$$\n","\n","This ensures:\n","- $A_{i,j} \\geq 0$ (all outputs are non-negative)\n","- $\\sum_{j=1}^{C} A_{i,j} = 1$ (rows sum to 1, valid probability distribution).\n","\n","### Step 2: Cross-Entropy Loss\n","\n","If $Y_i$ is the true label for sample $i$ (an integer in $[0, C-1]$),  \n","the cross-entropy loss for one sample is:\n","\n","$$\n","\\ell_i = -\\log\\big( A_{i, Y_i} \\big)\n","$$\n","\n","The loss over the batch is the average:\n","\n","$$\n","\\mathcal{L} = \\frac{1}{m} \\sum_{i=1}^m \\ell_i\n","= -\\frac{1}{m} \\sum_{i=1}^m \\log\\big( A_{i, Y_i} \\big)\n","$$\n","\n","### Step 3: Gradient (Backward Pass)\n","\n","The derivative of the loss with respect to the logits is elegant:\n","\n","$$\n","\\frac{\\partial \\mathcal{L}}{\\partial Z_{i,j}}\n","= A_{i,j} - \\mathbf{1}[j = Y_i]\n","$$\n","\n","That is:\n","- For the correct class: $A_{i,Y_i} - 1$\n","- For other classes: $A_{i,j}$\n","\n","This makes backpropagation very efficient.\n","\n","---\n","\n","### Summary\n","\n","- **Forward pass:** compute softmax + cross-entropy.  \n","- **Backward pass:** subtract 1 from the probability of the true class.  \n","\n","This loss is standard for multi-class classification problems such as MNIST.\n","\n","---\n","\n","We can express this more compactly in **matrix form**.\n","\n","Let:\n","- $ A \\in \\mathbb{R}^{m \\times C} $ be the matrix of softmax outputs,  \n","- $ Y \\in \\mathbb{R}^{m \\times C} $ be the one-hot encoded true labels,  \n","- $ m $ = batch size.  \n","\n","Then the gradient of the loss w.r.t. the logits $Z$ is:\n","\n","$$\n","\\frac{\\partial \\mathcal{L}}{\\partial Z} = \\frac{1}{m}\\,(A - Y)\n","$$\n","\n","---\n","\n","### Key Points:\n","- The subtraction $$ A - Y $$ automatically applies the correct rule to all classes in all samples.\n","- The factor $ \\tfrac{1}{m} $ appears if the loss is averaged across the batch (omit it if summing).\n","- This compact vectorized form makes backpropagation efficient in practice."],"metadata":{"id":"u651tX8vVVPp"}},{"cell_type":"code","source":["class CrossEntropyFromLogits:\n","    \"\"\"\n","    Implements the combination of:\n","    - Softmax activation (from raw logits)\n","    - Cross-entropy loss\n","\n","    This is a common choice for multi-class classification.\n","    \"\"\"\n","\n","    def forward(self, Z, Y):\n","        \"\"\"\n","        Forward pass: compute the cross-entropy loss from raw logits.\n","\n","        Args:\n","            Z (torch.Tensor): Logits (unnormalized scores) of shape (batch_size, n_classes).\n","            Y (torch.Tensor): True class indices of shape (batch_size,).\n","\n","        Returns:\n","            loss torch.Tensor: Scalar value of the cross-entropy loss.\n","        \"\"\"\n","        self.Y = Y  # Store true labels for backward pass\n","\n","        # TODO: Compute softmax probabilities (convert logits to probabilities)\n","        # self.A = ...\n","\n","        # TODO: Compute log-softmax (log probabilities)\n","        # log_softmax_Z = ...\n","\n","        # TODO: Select the log-probabilities of the correct classes for each sample\n","        # log_probs = ...\n","\n","        # TODO: Cross-entropy loss: average negative log-likelihood\n","        # loss = ...\n","\n","        return loss\n","\n","    def backward(self, n_classes):\n","        \"\"\"\n","        Backward pass: compute the gradient of the loss with respect to logits Z.\n","\n","        Args:\n","            n_classes (int): Number of classes in the classification problem.\n","\n","        Returns:\n","            torch.Tensor: Gradient dZ of shape (batch_size, n_classes).\n","        \"\"\"\n","        # TODO: One-hot encode the true labels\n","        # Y_one_hot = ...\n","\n","        # TODO: Derivative of cross-entropy w.r.t logits: softmax_output - one_hot_labels\n","        # dZ = ...\n","\n","        return dZ\n","\n","# Example usage\n","CELoss = CrossEntropyFromLogits()\n","Y = torch.randint(0, 3, (n_batch,))\n","loss = CELoss.forward(Z, Y)\n","print(loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZYsEzaRBeKj","executionInfo":{"status":"ok","timestamp":1755028466569,"user_tz":300,"elapsed":6,"user":{"displayName":"Juan David Martinez Vargas","userId":"15315348669826032119"}},"outputId":"47620091-b361-4773-d075-f31634a9a434"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.9861, device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["## 4. Training Loop — Forward, Backward, Manual Parameter Updates (No Optimizers Yet)\n","\n","In this section you’ll complete the **core learning cycle** using only the pieces we’ve built:\n","1. **Forward pass:** compute logits \\(Z\\) from inputs \\(X\\).\n","2. **Loss:** compute cross-entropy from logits and labels.\n","3. **Backward (loss):** compute \\(dZ = \\partial \\mathcal{L} / \\partial Z\\) (vectorized).\n","4. **Backward (network):** backpropagate \\(dZ\\) through layers to fill per-parameter grads.\n","5. **Manual update:** call `net.update(learning_rate)` to apply **plain SGD** updates.\n","\n","### TODOs (what you must fill in)\n","- [ ] **Forward:** `Z = net.forward(X)`\n","- [ ] **Loss:** `loss = CELoss.forward(Z, Y)`\n","- [ ] **Backward (loss):** `dZ = CELoss.backward(n_classes)`  (matrix form \\(A - Y\\); include \\(1/m\\) if you average)\n","- [ ] **Backward (network):** `net.backward(dZ)`\n","- [ ] **Update:** `net.update(learning_rate)`  *(manual SGD; no optimizer classes yet)*\n","- [ ] **Metrics:** accumulate running loss/accuracy for train and val\n","\n","**Tips**\n","- Average your **layer gradients** by batch size in each layer (e.g., `dW /= m`) for LR stability.\n","- Keep **validation/test** forward-only (no `backward`, no `update`).\n","- If you want to tweak LR per epoch, just modify the variable `learning_rate` before the loop or inside it."],"metadata":{"id":"I4lVIwb9YLCF"}},{"cell_type":"code","source":["history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n","batch_losses = []  # per-batch losses for the plot\n","\n","for epoch in range(1, num_epochs + 1):\n","    # -------- TRAIN --------\n","    if hasattr(net, \"train\"): net.train()\n","    running_loss, tot_correct, tot_samples = 0.0, 0, 0\n","    total_batches = len(trainloader)\n","\n","    pbar = tqdm(trainloader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\")\n","    for batch_idx, (images, labels) in enumerate(pbar, 1):\n","        X = images.view(images.size(0), -1).to(device)\n","        Y = labels.to(device)\n","\n","        # Forward\n","        Z = #TODO\n","        loss = #TODO\n","\n","        # Backward + update (manual autograd)\n","\n","\n","        # Stats\n","        running_loss += #TODO\n","        batch_losses.append(loss.detach().cpu().item())\n","        _, predicted = torch.max(Z, 1)\n","        tot_correct += (predicted == Y).sum().item()\n","        tot_samples += Y.size(0)\n","\n","        if batch_idx % max(1, total_batches // 10) == 0:\n","            pbar.set_postfix(loss=f\"{loss.item():.4f}\",\n","                             acc=f\"{tot_correct / max(1, tot_samples):.4f}\")\n","\n","    train_loss = #TODO\n","    train_acc = #TODO\n","\n","    # -------- VALIDATION --------\n","    if hasattr(net, \"eval\"): net.eval()\n","    val_running_loss, val_correct, val_samples = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(valloader, desc=f\"Epoch {epoch}/{num_epochs} [Val]\"):\n","            X = images.view(images.size(0), -1).to(device)\n","            Y = labels.to(device)\n","\n","            Z = #TODO\n","            vloss = #TODO\n","            val_running_loss += #TODO\n","\n","            _, predicted = torch.max(Z, 1)\n","            val_correct += (predicted == Y).sum().item()\n","            val_samples += Y.size(0)\n","\n","    val_loss = val_running_loss / len(valloader)\n","    val_acc = val_correct / val_samples\n","\n","    history[\"train_loss\"].append(train_loss)\n","    history[\"train_acc\"].append(train_acc)\n","    history[\"val_loss\"].append(val_loss)\n","    history[\"val_acc\"].append(val_acc)\n","\n","    print(f\"Epoch {epoch}/{num_epochs} | \"\n","          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n","          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n","\n","# -------- OPTIONAL TEST --------\n","if 'testloader' in globals() and testloader is not None:\n","    if hasattr(net, \"eval\"): net.eval()\n","    test_correct, test_samples, test_running_loss = 0, 0, 0.0\n","    with torch.no_grad():\n","        for images, labels in tqdm(testloader, desc=\"[Test]\"):\n","            X = images.view(images.size(0), -1).to(device)\n","            Y = labels.to(device)\n","            Z = #TODO\n","            loss = #TODO\n","            test_running_loss += #TODO\n","            _, pred = torch.max(Z, 1)\n","            test_correct += (pred == Y).sum().item()\n","            test_samples += Y.size(0)\n","    test_loss = test_running_loss / len(testloader)\n","    test_acc = test_correct / test_samples\n","    print(f\"[Test] Loss: {test_loss:.4f} | Acc: {test_acc:.4f}\")\n","\n","# -------- PLOTS --------\n","plt.figure(); plt.plot(np.array(batch_losses))\n","plt.xlabel('Batch'); plt.ylabel('Loss'); plt.title('Training Loss (per batch)'); plt.show()\n","\n","plt.figure(); plt.plot(history[\"train_loss\"], label='Train'); plt.plot(history[\"val_loss\"], label='Val')\n","plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss per Epoch'); plt.show()\n","\n","plt.figure(); plt.plot(history[\"train_acc\"], label='Train'); plt.plot(history[\"val_acc\"], label='Val')\n","plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.title('Accuracy per Epoch'); plt.show()"],"metadata":{"id":"TYINJm8iZakK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## The `Net` Class: A Simple Sequential Container\n","\n","To organize our neural network, we define a `Net` class that acts as a **sequential container of layers**.  \n","This class is inspired by frameworks like PyTorch, but implemented from scratch for educational purposes.\n","\n","### Key Responsibilities\n","\n","- **Layer Management:**  \n","  We can add layers (e.g., `Linear`, `ReLU`, `Dropout`) using `add()`.  \n","  Each layer must implement:\n","  - `forward()` — computes the output given inputs.  \n","  - `backward()` — computes the gradients of the loss w.r.t. its inputs.  \n","  - `update(lr)` — updates the trainable parameters (if any).  \n","\n","- **Training/Evaluation Modes:**  \n","  The class has `train()` and `eval()` methods.  \n","  These switch the whole network into training or evaluation mode, propagating the setting to layers that support it (like `Dropout`, which behaves differently during training vs evaluation).\n","\n","- **Forward and Backward Passes:**  \n","  - `forward(X)` runs the input through all layers in sequence.  \n","  - `backward(dZ)` propagates gradients in reverse order, from the output back to the input.  \n","\n","- **Parameter Updates:**  \n","  `update(lr)` applies gradient descent to all trainable layers, using the provided learning rate.  \n","  (Later we could replace this with more advanced optimizers like Adam or RMSProp.)\n","\n","### Next Steps\n","\n","- **TODOs:**  \n","  - Implement the details of each layer’s `forward()` and `backward()` functions.  \n","  - Add parameter updates inside `update()` for layers that have weights.  \n","  - Complete the training loop that uses this `Net` container to build and train a model on MNIST.  \n","\n","This design provides a clear and modular structure, making it easy to extend with new layers or optimizers."],"metadata":{"id":"sNZzsMcVd0Ro"}},{"cell_type":"code","source":["class Net:\n","    \"\"\"\n","    A simple sequential container for custom layers.\n","    Provides PyTorch-like train()/eval() switches and\n","    runs forward/backward/update across all layers.\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"\n","        Start with an empty list of layers and set the network\n","        to training mode by default.\n","        \"\"\"\n","        self.layers = []\n","        self.training = True  # True = training mode, False = eval mode\n","\n","    def add(self, layer):\n","        \"\"\"\n","        Add a layer to the network.\n","\n","        Args:\n","            layer: Any object that implements forward(), backward(), update(),\n","                   and (optionally) train()/eval() for mode control.\n","        \"\"\"\n","        self.layers.append(layer)\n","\n","    # ---- Mode control (pro-style) ----\n","    def train(self):\n","        \"\"\"\n","        Switch the whole network to training mode and propagate\n","        the setting to layers that implement train().\n","        \"\"\"\n","        self.training = True\n","        for layer in self.layers:\n","            if hasattr(layer, \"train\"):\n","                layer.train()\n","        return self\n","\n","    def eval(self):\n","        \"\"\"\n","        Switch the whole network to evaluation mode and propagate\n","        the setting to layers that implement eval().\n","        \"\"\"\n","        self.training = False\n","        for layer in self.layers:\n","            if hasattr(layer, \"eval\"):\n","                layer.eval()\n","        return self\n","\n","    # ---- Core passes ----\n","    def forward(self, X):\n","        \"\"\"\n","        Forward pass through all layers.\n","\n","        Args:\n","            X (torch.Tensor): Input to the network.\n","\n","        Returns:\n","            torch.Tensor: Output after the last layer.\n","        \"\"\"\n","        for layer in self.layers:\n","            #Implement the forward pass\n","            X = #TODO  # output of one layer becomes input to the next\n","        return X\n","\n","    def backward(self, dZ):\n","        \"\"\"\n","        Backward pass through all layers in reverse order.\n","\n","        Args:\n","            dZ (torch.Tensor): Gradient of the loss w.r.t. network output.\n","\n","        Returns:\n","            torch.Tensor: Gradient of the loss w.r.t. the network input.\n","        \"\"\"\n","        for layer in reversed(self.layers):\n","            #Implement the backward pass\n","            dZ = #TODO  # each layer returns grad for the previous one\n","        return dZ\n","\n","    def update(self, lr):\n","        \"\"\"\n","        Update parameters of all trainable layers with the given learning rate.\n","\n","        Args:\n","            lr (float): Learning rate.\n","        \"\"\"\n","        for layer in self.layers:\n","            # Some layers (e.g., activations) may not have parameters\n","            if hasattr(layer, \"update\"):\n","                layer.update(lr)"],"metadata":{"id":"1imEUcxliTJK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Testing the Implementation\n","\n","The following cells are intended as a **first test** of the network implementation.  \n","We build a simple architecture with two linear layers and train it using our custom  \n","cross-entropy loss. Since we have not yet introduced any **non-linear activation functions**,  \n","this setup is equivalent to a **softmax regression model** (a linear classifier).  \n","\n","The purpose here is to verify that the forward pass, backward pass, parameter updates,  \n","and loss tracking are working correctly before moving on to more complex networks."],"metadata":{"id":"1_jy5PSCm4on"}},{"cell_type":"code","source":["# Check if CUDA is available and set the device accordingly\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# Forcing the device to CPU (this line will override the previous check)\n","device = 'cpu'\n","\n","# Define the number of input features and output classes\n","n_features = 784\n","n_classes = 10\n","\n","# Initialize the network (assuming `Net` is a custom class that you've defined)\n","net = Net()\n","\n","# Add a linear layer to the network with 784 input features and 1024 output features\n","net.add(Linear(n_features, 1024, device=device))\n","\n","# Add another linear layer with 1024 input features and 10 output features\n","net.add(Linear(1024, n_classes, device=device))\n","\n","# Initialize the custom cross-entropy loss function from logits\n","CEloss = CrossEntropyFromLogits()"],"metadata":{"id":"9Y0eoXyzjExZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the learning rate\n","learning_rate = 0.001\n","history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n","batch_losses = []  # per-batch losses for the plot\n","\n","for epoch in range(1, num_epochs + 1):\n","    # -------- TRAIN --------\n","    if hasattr(net, \"train\"): net.train()\n","    running_loss, tot_correct, tot_samples = 0.0, 0, 0\n","    total_batches = len(trainloader)\n","\n","    pbar = tqdm(trainloader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\")\n","    for batch_idx, (images, labels) in enumerate(pbar, 1):\n","        X = images.view(images.size(0), -1).to(device)\n","        Y = labels.to(device)\n","\n","        # Forward\n","        Z = net.forward(X)\n","        loss = CELoss.forward(Z, Y)\n","\n","        # Backward + update (manual autograd)\n","        dZ = CELoss.backward(n_classes)\n","        _ = net.backward(dZ)\n","        net.update(learning_rate)\n","\n","        # Stats\n","        running_loss += loss.item()\n","        batch_losses.append(loss.detach().cpu().item())\n","        _, predicted = torch.max(Z, 1)\n","        tot_correct += (predicted == Y).sum().item()\n","        tot_samples += Y.size(0)\n","\n","        if batch_idx % max(1, total_batches // 10) == 0:\n","            pbar.set_postfix(loss=f\"{loss.item():.4f}\",\n","                             acc=f\"{tot_correct / max(1, tot_samples):.4f}\")\n","\n","    train_loss = running_loss / total_batches\n","    train_acc = tot_correct / tot_samples\n","\n","    # -------- VALIDATION --------\n","    if hasattr(net, \"eval\"): net.eval()\n","    val_running_loss, val_correct, val_samples = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(valloader, desc=f\"Epoch {epoch}/{num_epochs} [Val]\"):\n","            X = images.view(images.size(0), -1).to(device)\n","            Y = labels.to(device)\n","\n","            Z = net.forward(X)\n","            vloss = CELoss.forward(Z, Y)\n","            val_running_loss += vloss.item()\n","\n","            _, predicted = torch.max(Z, 1)\n","            val_correct += (predicted == Y).sum().item()\n","            val_samples += Y.size(0)\n","\n","    val_loss = val_running_loss / len(valloader)\n","    val_acc = val_correct / val_samples\n","\n","    history[\"train_loss\"].append(train_loss)\n","    history[\"train_acc\"].append(train_acc)\n","    history[\"val_loss\"].append(val_loss)\n","    history[\"val_acc\"].append(val_acc)\n","\n","    print(f\"Epoch {epoch}/{num_epochs} | \"\n","          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n","          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n","\n","# -------- OPTIONAL TEST --------\n","if 'testloader' in globals() and testloader is not None:\n","    if hasattr(net, \"eval\"): net.eval()\n","    test_correct, test_samples, test_running_loss = 0, 0, 0.0\n","    with torch.no_grad():\n","        for images, labels in tqdm(testloader, desc=\"[Test]\"):\n","            X = images.view(images.size(0), -1).to(device)\n","            Y = labels.to(device)\n","            Z = net.forward(X)\n","            loss = CELoss.forward(Z, Y)\n","            test_running_loss += loss.item()\n","            _, pred = torch.max(Z, 1)\n","            test_correct += (pred == Y).sum().item()\n","            test_samples += Y.size(0)\n","    test_loss = test_running_loss / len(testloader)\n","    test_acc = test_correct / test_samples\n","    print(f\"[Test] Loss: {test_loss:.4f} | Acc: {test_acc:.4f}\")\n","\n","# -------- PLOTS --------\n","plt.figure(); plt.plot(np.array(batch_losses))\n","plt.xlabel('Batch'); plt.ylabel('Loss'); plt.title('Training Loss (per batch)'); plt.show()\n","\n","plt.figure(); plt.plot(history[\"train_loss\"], label='Train'); plt.plot(history[\"val_loss\"], label='Val')\n","plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss per Epoch'); plt.show()\n","\n","plt.figure(); plt.plot(history[\"train_acc\"], label='Train'); plt.plot(history[\"val_acc\"], label='Val')\n","plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.title('Accuracy per Epoch'); plt.show()"],"metadata":{"id":"NqhIE7mKlTtO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ReLU Activation Layer\n","\n","The **Rectified Linear Unit (ReLU)** is one of the most widely used activation functions in deep learning.  \n","It introduces **non-linearity** into the network by applying a simple element-wise rule:\n","\n","$$\n","a = \\text{ReLU}(z) = \\max(0, z)\n","$$\n","\n","- **Forward Pass**:  \n","  Each element of the input tensor \\( Z \\) is mapped to itself if it is positive, or zero if it is negative.  \n","  This helps prevent the \"squashing\" effect of sigmoid/tanh and allows gradients to flow more effectively.\n","\n","- **Backward Pass**:  \n","  The gradient is passed unchanged for inputs greater than zero and is set to zero for inputs less than or equal to zero:\n","\n","  $$\n","  \\frac{\\partial a}{\\partial z} =\n","  \\begin{cases}\n","  1 & \\text{if } z > 0 \\\\\n","  0 & \\text{if } z \\leq 0\n","  \\end{cases}\n","  $$\n","\n","- **Update Step**:  \n","  ReLU has no trainable parameters, so its `update()` method is left empty.\n","\n","This layer is essential because it allows neural networks to model complex non-linear decision boundaries while remaining computationally efficient.\n"],"metadata":{"id":"t--JpzANm2Fz"}},{"cell_type":"code","source":["class ReLU:\n","    \"\"\"\n","    ReLU activation layer.\n","    \"\"\"\n","\n","    def forward(self, Z):\n","        \"\"\"\n","        Perform the forward pass of the ReLU activation function.\n","\n","        Args:\n","            Z (torch.Tensor): Input tensor.\n","\n","        Returns:\n","            A torch.Tensor: Output tensor with ReLU applied element-wise.\n","        \"\"\"\n","        self.A = #TODO\n","        return self.A\n","\n","    def backward(self, dA):\n","        \"\"\"\n","        Perform the backward pass of the ReLU activation function.\n","\n","        Args:\n","            dA (torch.Tensor): Gradient of the loss with respect to the output.\n","\n","        Returns:\n","            dZ torch.Tensor: Gradient of the loss with respect to the input.\n","        \"\"\"\n","        dZ = #TODO\n","\n","        return dZ\n","\n","    def update(self,lr):\n","        \"\"\"\n","        ReLU does not have any parameters to update.\n","        \"\"\"\n","        pass\n"],"metadata":{"id":"tmEUvk1dod-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if CUDA is available and set the device accordingly\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# Forcing the device to CPU (this line will override the previous check)\n","device = 'cpu'\n","\n","# Define the number of input features and output classes\n","n_features = 784\n","n_classes = 10\n","\n","# Initialize the network (assuming `Net` is a custom class that you've defined)\n","net = Net()\n","\n","# Add a linear layer to the network with 784 input features and 1024 output features\n","net.add(Linear(n_features, 1024, device=device))\n","\n","# Add a non-linear activation function\n","net.add(ReLU())\n","\n","# Add another linear layer with 1024 input features and 10 output features\n","net.add(Linear(1024, n_classes, device=device))\n","\n","# Initialize the custom cross-entropy loss function from logits\n","CEloss = CrossEntropyFromLogits()"],"metadata":{"id":"rRQxxSRlph7k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the learning rate\n","learning_rate = 0.001\n","history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n","batch_losses = []  # per-batch losses for the plot\n","\n","for epoch in range(1, num_epochs + 1):\n","    # -------- TRAIN --------\n","    if hasattr(net, \"train\"): net.train()\n","    running_loss, tot_correct, tot_samples = 0.0, 0, 0\n","    total_batches = len(trainloader)\n","\n","    pbar = tqdm(trainloader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\")\n","    for batch_idx, (images, labels) in enumerate(pbar, 1):\n","        X = images.view(images.size(0), -1).to(device)\n","        Y = labels.to(device)\n","\n","        # Forward\n","        Z = net.forward(X)\n","        loss = CELoss.forward(Z, Y)\n","\n","        # Backward + update (manual autograd)\n","        dZ = CELoss.backward(n_classes)\n","        _ = net.backward(dZ)\n","        net.update(learning_rate)\n","\n","        # Stats\n","        running_loss += loss.item()\n","        batch_losses.append(loss.detach().cpu().item())\n","        _, predicted = torch.max(Z, 1)\n","        tot_correct += (predicted == Y).sum().item()\n","        tot_samples += Y.size(0)\n","\n","        if batch_idx % max(1, total_batches // 10) == 0:\n","            pbar.set_postfix(loss=f\"{loss.item():.4f}\",\n","                             acc=f\"{tot_correct / max(1, tot_samples):.4f}\")\n","\n","    train_loss = running_loss / total_batches\n","    train_acc = tot_correct / tot_samples\n","\n","    # -------- VALIDATION --------\n","    if hasattr(net, \"eval\"): net.eval()\n","    val_running_loss, val_correct, val_samples = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(valloader, desc=f\"Epoch {epoch}/{num_epochs} [Val]\"):\n","            X = images.view(images.size(0), -1).to(device)\n","            Y = labels.to(device)\n","\n","            Z = net.forward(X)\n","            vloss = CELoss.forward(Z, Y)\n","            val_running_loss += vloss.item()\n","\n","            _, predicted = torch.max(Z, 1)\n","            val_correct += (predicted == Y).sum().item()\n","            val_samples += Y.size(0)\n","\n","    val_loss = val_running_loss / len(valloader)\n","    val_acc = val_correct / val_samples\n","\n","    history[\"train_loss\"].append(train_loss)\n","    history[\"train_acc\"].append(train_acc)\n","    history[\"val_loss\"].append(val_loss)\n","    history[\"val_acc\"].append(val_acc)\n","\n","    print(f\"Epoch {epoch}/{num_epochs} | \"\n","          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n","          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n","\n","# -------- OPTIONAL TEST --------\n","if 'testloader' in globals() and testloader is not None:\n","    if hasattr(net, \"eval\"): net.eval()\n","    test_correct, test_samples, test_running_loss = 0, 0, 0.0\n","    with torch.no_grad():\n","        for images, labels in tqdm(testloader, desc=\"[Test]\"):\n","            X = images.view(images.size(0), -1).to(device)\n","            Y = labels.to(device)\n","            Z = net.forward(X)\n","            loss = CELoss.forward(Z, Y)\n","            test_running_loss += loss.item()\n","            _, pred = torch.max(Z, 1)\n","            test_correct += (pred == Y).sum().item()\n","            test_samples += Y.size(0)\n","    test_loss = test_running_loss / len(testloader)\n","    test_acc = test_correct / test_samples\n","    print(f\"[Test] Loss: {test_loss:.4f} | Acc: {test_acc:.4f}\")\n","\n","# -------- PLOTS --------\n","plt.figure(); plt.plot(np.array(batch_losses))\n","plt.xlabel('Batch'); plt.ylabel('Loss'); plt.title('Training Loss (per batch)'); plt.show()\n","\n","plt.figure(); plt.plot(history[\"train_loss\"], label='Train'); plt.plot(history[\"val_loss\"], label='Val')\n","plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss per Epoch'); plt.show()\n","\n","plt.figure(); plt.plot(history[\"train_acc\"], label='Train'); plt.plot(history[\"val_acc\"], label='Val')\n","plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.title('Accuracy per Epoch'); plt.show()"],"metadata":{"id":"xCBYBn9Dp5mv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Extending the Neural Network\n","\n","At this point, we have implemented the essential components of a neural network:  \n","- **Linear transformations (fully connected layers)** to project data into new spaces,  \n","- **Non-linear activation functions** such as ReLU to introduce complexity and allow the network to model non-linear relationships, and  \n","- **A cost function (e.g., Cross-Entropy)** to measure the discrepancy between predictions and true labels.  \n","\n","While this setup already allows us to train a functional neural network, more advanced operations can significantly improve performance and generalization. Two of the most important techniques are:  \n","\n","- **Dropout**: Randomly disables a fraction of neurons during training, preventing co-adaptation and reducing overfitting.  \n","- **Batch Normalization**: Normalizes intermediate activations across a mini-batch, stabilizing training and often accelerating convergence.  \n","\n","Adding these operations will bring our implementation closer to modern deep learning practices, making the models both more robust and efficient.\n"],"metadata":{"id":"L94-47vRosR6"}},{"cell_type":"markdown","source":["### Batch Normalization\n","\n","Batch Normalization (BN) is used to stabilize and accelerate training by normalizing activations.  \n","Given input activations $X \\in \\mathbb{R}^{m \\times d}$ (batch size $m$, features $d$):\n","\n","---\n","\n","**Training mode**\n","\n","Batch statistics:  \n","$$\n","\\mu_{\\mathrm{B}}=\\frac{1}{m}\\sum_{i=1}^m X_i\n","$$  \n","$$\n","\\sigma^2_{\\mathrm{B}}=\\frac{1}{m}\\sum_{i=1}^m \\left(X_i-\\mu_{\\mathrm{B}}\\right)^2\n","$$\n","\n","Normalize, then scale/shift:  \n","$$\n","\\hat{X}_i=\\frac{X_i-\\mu_{\\mathrm{B}}}{\\sqrt{\\sigma^2_{\\mathrm{B}}+\\varepsilon}}\n","$$  \n","$$\n","Y_i=\\gamma\\,\\hat{X}_i+\\beta\n","$$\n","\n","Update running (EMA) statistics with momentum $\\alpha$:  \n","$$\n","\\mu_{\\mathrm{R}} \\leftarrow (1-\\alpha)\\,\\mu_{\\mathrm{R}} + \\alpha\\,\\mu_{\\mathrm{B}}\n","$$  \n","$$\n","\\sigma^2_{\\mathrm{R}} \\leftarrow (1-\\alpha)\\,\\sigma^2_{\\mathrm{R}} + \\alpha\\,\\sigma^2_{\\mathrm{B}}\n","$$\n","\n","---\n","\n","**Inference mode**\n","\n","Use stored running statistics (no updates):  \n","$$\n","\\hat{X}_i=\\frac{X_i-\\mu_{\\mathrm{R}}}{\\sqrt{\\sigma^2_{\\mathrm{R}}+\\varepsilon}}\n","$$  \n","$$\n","Y_i=\\gamma\\,\\hat{X}_i+\\beta\n","$$\n","\n","---\n","\n","**Summary:**  \n","- **Training:** use $(\\mu_{\\mathrm{B}}, \\sigma^2_{\\mathrm{B}})$, normalize, scale/shift, update $(\\mu_{\\mathrm{R}}, \\sigma^2_{\\mathrm{R}})$.  \n","- **Inference:** use $(\\mu_{\\mathrm{R}}, \\sigma^2_{\\mathrm{R}})$ collected during training, normalize, scale/shift, **no updates**.\n","\n","---\n","\n","### Task\n","\n","Implement **BatchNorm as a class** with the following:\n","\n","- **Forward pass (`forward`)**  \n","  - #TODO compute batch mean $\\mu_{\\mathrm{B}}$ and variance $\\sigma^2_{\\mathrm{B}}$ (training)  \n","  - #TODO normalize input $X$  \n","  - #TODO scale and shift using $\\gamma, \\beta$  \n","  - #TODO update running mean/variance (training only)  \n","  - #TODO use running statistics in inference mode  \n","\n","- **Backward pass (`backward`)**  \n","  - #TODO compute gradient of loss w.r.t. $\\hat{X}$  \n","  - #TODO propagate through normalization to get $dX$  \n","  - #TODO compute gradients w.r.t. parameters $\\gamma, \\beta$  \n","\n","- **Update parameters (`update`)**  \n","  - #TODO update $\\gamma, \\beta$ using the learning rate\n"],"metadata":{"id":"6GxeamCV5qEY"}},{"cell_type":"code","source":["class BatchNorm1D:\n","    \"\"\"\n","    Batch Normalization for 2D inputs: (batch, features).\n","\n","    TRAIN: compute batch stats, normalize, update running stats, support backward().\n","    EVAL:  use running stats, no updates, typically no backward().\n","    \"\"\"\n","\n","    def __init__(self, n_features, eps=1e-5, momentum=0.1, device=\"cpu\"):\n","        self.eps = eps\n","        self.momentum = momentum\n","        self.device = device\n","\n","        # Learnable affine parameters\n","        self.gamma = torch.ones(n_features, device=device, requires_grad=False)\n","        self.beta  = torch.zeros(n_features, device=device, requires_grad=False)\n","\n","        # Running (inference) statistics\n","        self.running_mean = torch.zeros(n_features, device=device, requires_grad=False)\n","        self.running_var  = torch.ones(n_features,  device=device, requires_grad=False)\n","\n","        # Mode flag\n","        self.training = True\n","\n","        # Caches for backward\n","        self.X = None\n","        self.X_hat = None\n","        self.batch_mean = None\n","        self.batch_var = None\n","        self.std = None\n","\n","        # Grads for parameters\n","        self.dgamma = None\n","        self.dbeta  = None\n","\n","    def train(self): self.training = True;  return self\n","    def eval(self):  self.training = False; return self\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Args:\n","            X: (batch, features)\n","        Returns:\n","            Y: (batch, features)\n","        \"\"\"\n","        if self.training:\n","            # ===== TODO: compute batch statistics along batch dim =====\n","            # self.batch_mean = ...\n","            # self.batch_var  = ...  # use unbiased=False\n","            # ===== TODO: compute std and normalized activations =====\n","            # self.std   = ...\n","            # self.X_hat = ...\n","            #\n","            # ===== TODO: update running stats (EMA) =====\n","            # self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * self.batch_mean\n","            # self.running_var  = (1 - self.momentum) * self.running_var  + self.momentum * self.batch_var\n","            pass\n","        else:\n","            # ===== TODO: inference normalization using running stats =====\n","            # self.std   = ...\n","            # self.X_hat = ...\n","            pass\n","\n","        # Cache input for backward\n","        self.X = X\n","\n","        # ===== TODO: affine transform Y = gamma * X_hat + beta =====\n","        # Y = ...\n","        # return Y\n","        pass\n","\n","    def backward(self, dY):\n","        \"\"\"\n","        Args:\n","            dY: upstream gradient (batch, features)\n","        Returns:\n","            dX: gradient wrt input X (batch, features)\n","        \"\"\"\n","        if not self.training:\n","            # In this teaching framework we forbid backward in eval to emphasize the distinction.\n","            raise RuntimeError(\"Backward called in eval() mode. Use training mode for gradient computation.\")\n","\n","        m = dY.size(0)  # batch size\n","\n","        # ===== TODO: parameter gradients =====\n","        # self.dbeta  = ...\n","        # self.dgamma = ...\n","\n","        # ===== TODO: gradient wrt normalized activations =====\n","        # dx_hat = ...\n","\n","        # The following hints reflect the standard BN backward derivation:\n","        # x_mu   = self.X - self.batch_mean\n","        # invstd = 1.0 / self.std\n","        #\n","        # ===== TODO: compute dvar and dmean using cached tensors =====\n","        # dvar  = torch.sum(dx_hat * x_mu * -0.5 * (invstd ** 3), dim=0)\n","        # dmean = torch.sum(-dx_hat * invstd, dim=0) + dvar * torch.mean(-2.0 * x_mu, dim=0)\n","        #\n","        # ===== TODO: put it all together to get dX =====\n","        # dX = dx_hat * invstd + (2.0 / m) * x_mu * dvar + dmean / m\n","        #\n","        # return dX\n","        pass\n","\n","    def update(self, lr):\n","        \"\"\"\n","        Simple SGD update for gamma and beta.\n","        \"\"\"\n","        # ===== TODO: apply SGD step to gamma and beta =====\n","        # self.gamma -= lr * self.dgamma\n","        # self.beta  -= lr * self.dbeta\n","        pass\n"],"metadata":{"id":"lu09TUDa5Re_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Inverted Dropout ###\n","\n","Let:  \n","$ p = \\text{drop probability (fraction of units set to zero in training)}$\n","$ q = 1-p = \\text{keep probability} $\n","$ X \\in \\mathbb{R}^{m \\times d} = \\text{activations (batch } m, \\text{ features } d) $\n","$ M \\in \\left\\{ 0, \\frac{1}{q} \\right\\}^{m \\times d} = \\text{dropout mask} $\n","\n","---\n","\n","**Training mode:**\n","\n","We sample the mask $$ M $$ as:\n","$$\n","M_{ij} =\n","\\begin{cases}\n","\\frac{1}{q}, & \\text{with probability } q, \\\\\n","0, & \\text{with probability } p\n","\\end{cases}\n","$$\n","\n","Then the output is:\n","$$\n","Y = X \\odot M\n","$$\n","\n","**Expected value during training:**\n","$$\n","\\mathbb{E}[Y] = \\mathbb{E}[X \\odot M] = X \\cdot \\mathbb{E}[M] = X \\cdot \\left(q \\cdot \\frac{1}{q} + p \\cdot 0\\right) = X\n","$$\n","\n","Thus, the expected activations in training match those in inference.\n","\n","---\n","\n","**Inference mode:**\n","\n","No dropout, no scaling:\n","$$\n","Y = X\n","$$\n","\n","Since training already scaled the kept units by $$ \\tfrac{1}{q} $$, the magnitude matches without extra work.\n","\n","---\n","\n","**Why not multiply by $ p $?**\n","\n","Multiplying by $ p $ would shrink the kept activations instead of preserving their expected value:\n","$$\n","\\mathbb{E}[Y] = X \\cdot p \\quad \\neq \\quad X\n","$$\n","\n","That would require extra scaling at inference, which *inverted dropout* avoids.\n","\n","---\n","\n","**Summary:**\n","\n","**Training:**  \n","$$\n","Y = X \\odot M, \\quad M_{ij} \\in \\left\\{0, \\tfrac{1}{1-p}\\right\\}\n","$$\n","\n","**Inference:**  \n","$$\n","Y = X\n","$$\n","\n","Property preserved:  \n","$$\n","\\mathbb{E}[Y] = X\n","$$\n","\n","---\n","\n","### ✅ Task\n","\n","- Implement an **`Inverted Dropout`** layer with the following methods:  \n","  - `forward(X)`:  \n","    - In **training mode**, apply mask $$ M $$ as above.  \n","    - In **evaluation mode**, return $$ X $$.  \n","  - `backward(dY)`: propagate gradients through the same mask.  \n","  - `train()` / `eval()`: toggle between training and inference modes.  \n","  - `update(lr)`: no parameters to update, but include for API consistency.  \n","\n","- Verify by simulation that:  \n","  1. The expected output of the dropout layer in **training** matches the original input.  \n","  2. No scaling is needed in **evaluation**.\n"],"metadata":{"id":"xtu3_Meh8eBH"}},{"cell_type":"code","source":["import torch\n","\n","class Dropout:\n","    \"\"\"\n","    Inverted Dropout (for fully-connected tensors [batch, features]).\n","\n","    - TRAIN: randomly zeroes activations with prob p, and rescales by 1/(1-p)\n","             so the expected activation stays constant.\n","    - EVAL:  identity (no dropout, no scaling).\n","\n","    Students must implement the forward and backward passes.\n","    \"\"\"\n","\n","    def __init__(self, p=0.5, device=\"cpu\"):\n","        \"\"\"\n","        Args:\n","            p (float): Drop probability in [0,1). Typical values: 0.1~0.5\n","            device (str): 'cpu' or 'cuda'\n","        \"\"\"\n","        assert 0.0 <= p < 1.0, \"p must be in [0, 1).\"\n","        self.p = p\n","        self.device = device\n","        self.training = True\n","        self.mask = None  # cache for backward\n","\n","    # Mode control\n","    def train(self):\n","        self.training = True\n","        return self\n","\n","    def eval(self):\n","        self.training = False\n","        return self\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Forward pass of dropout.\n","\n","        Args:\n","            X: Tensor of shape (batch, features)\n","        Returns:\n","            Tensor of same shape\n","        \"\"\"\n","        if self.training and self.p > 0.0:\n","            # TODO: Implement inverted dropout\n","            # 1. Compute keep_prob = 1 - p\n","            # 2. Sample a Bernoulli mask with probability keep_prob\n","            # 3. Scale the mask by 1 / keep_prob\n","            # 4. Multiply X by the mask and return\n","            pass\n","        else:\n","            # TODO: In eval mode, dropout is a no-op\n","            # Return X unchanged and store a mask of ones for backward\n","            pass\n","\n","    def backward(self, dY):\n","        \"\"\"\n","        Backward pass of dropout.\n","\n","        Args:\n","            dY: Gradient wrt output, shape (batch, features)\n","        Returns:\n","            dX: Gradient wrt input, shape (batch, features)\n","        \"\"\"\n","        # TODO: Backprop through dropout\n","        # TRAIN: dX = dY * mask\n","        # EVAL:  dX = dY\n","        pass\n","\n","    def update(self, lr):\n","        \"\"\"\n","        No learnable parameters in Dropout, so nothing to update.\n","        Kept for API consistency.\n","        \"\"\"\n","        pass\n","\n"],"metadata":{"id":"m-ePO-1o7-_x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Final Task — Put It All Together\n","\n","In this capstone exercise you will **assemble a complete mini deep-learning stack** and use it to train MNIST models. You’ll integrate **Linear**, **ReLU**, **BatchNorm1D**, and **Dropout**, write a clean **training/validation loop**, experiment with **different architectures**, and finally **package your code** into a reusable Python module.\n","\n","### What to Build\n","\n","1. **Model Architectures (experiment)**\n","   - Start with a baseline: `Linear(784→10)` (softmax regression).\n","   - Add depth + non-linearities:\n","     - Example A: `Linear(784→256) → ReLU → Linear(256→10)`\n","     - Example B: `Linear(784→256) → BatchNorm1D → ReLU → Dropout(p=0.2) → Linear(256→10)`\n","     - Example C (deeper): `784→512→BatchNorm→ReLU→Dropout→256→BatchNorm→ReLU→Dropout→10`\n","   - Try **2–3 architectures**. Log train/val loss & accuracy per epoch.\n","\n","2. **Training Loop (manual updates, no optimizers yet)**\n","   - Forward → Loss (CrossEntropyFromLogits) → Backward (matrix form) → `net.backward(dZ)` → `net.update(lr)`.\n","   - Validation after each epoch (no grads, no updates).\n","   - Record to `history = {\"train_loss\",\"train_acc\",\"val_loss\",\"val_acc\"}`.\n","   - Plots: per-batch loss; per-epoch loss/accuracy (train vs. val).\n","\n","3. **Regularization & Stabilization**\n","   - **Dropout:** compare `p ∈ {0.0, 0.2, 0.5}`.\n","   - **BatchNorm:** place BN **before** ReLU in FC blocks (common practice).\n","   - Optional extras (if time): weight decay (L2), gradient clipping, LR schedule.\n","\n","4. **Packaging Your Framework**\n","   - Create a single file **`minitorch.py`** with all components:\n","     - Layers: `Linear`, `ReLU`, `BatchNorm1D`, `Dropout`\n","     - Loss: `CrossEntropyFromLogits`\n","     - Container: `Net`\n","     - (Optional) utility functions (e.g., accuracy)\n","   - Import it from your notebook and train.\n","\n","---\n","\n","### Deliverables\n","\n","- **Notebook results:**\n","  - Table or brief summary of architectures tried, best val accuracy, and comments.\n","  - Training curves (loss & accuracy) showing the effect of BN/Dropout.\n","- **`minitorch.py`** file with clean docstrings and minimal dependencies.\n","\n","---\n","\n","### Suggested Evaluation Protocol\n","\n","- Use the same **train/val split** across runs (fix a seed).\n","- Train for **~5–10 epochs** (enough to see trends).\n","- Report **best validation accuracy** and final **test accuracy** for your top model.\n","- Briefly explain **what helped** (BN, Dropout, depth) and **why**.\n","\n","---\n","\n","### Checklist / TODOs\n","\n","- [ ] Implement **forward** and **backward** in `Linear`, `ReLU`, `BatchNorm1D`, `Dropout`.\n","- [ ] Implement **CrossEntropyFromLogits** with vectorized gradient \\(dZ = A - Y\\).\n","- [ ] Write training loop with **manual parameter updates** (`net.update(lr)`).\n","- [ ] Add **BatchNorm** and **Dropout** in your architectures and compare.\n","- [ ] Track and plot **history** for train/val.\n","- [ ] Save best model metrics and briefly **analyze results**.\n","- [ ] Package everything into **`minitorch.py`** and re-run using imports.\n","\n","---\n","\n","### Example `minitorch.py` Skeleton (fill in your implementations)\n","\n","```python\n","# minitorch.py\n","import torch\n","\n","class Net:\n","    def __init__(self): self.layers=[]; self.training=True\n","    def add(self, layer): self.layers.append(layer)\n","    def train(self): self.training=True; [getattr(l,'train',lambda:None)() for l in self.layers]; return self\n","    def eval(self):  self.training=False;[getattr(l,'eval', lambda:None)() for l in self.layers]; return self\n","    def forward(self, X):\n","        for layer in self.layers: X = layer.forward(X)\n","        return X\n","    def backward(self, dZ):\n","        for layer in reversed(self.layers): dZ = layer.backward(dZ)\n","        return dZ\n","    def update(self, lr):\n","        for layer in self.layers:\n","            if hasattr(layer, \"update\"): layer.update(lr)\n","\n","class Linear:\n","    # TODO: init (W,b), forward, backward (avg grads), update, parameters (optional)\n","    ...\n","\n","class ReLU:\n","    # TODO: forward (max(0,z)), backward (mask), update (pass)\n","    ...\n","\n","class BatchNorm1D:\n","    # TODO: forward (train/infer paths, EMA), backward (γ, β, dX), update\n","    ...\n","\n","class Dropout:\n","    # TODO: forward (inverted dropout), backward (mask), update (pass)\n","    ...\n","\n","class CrossEntropyFromLogits:\n","    # TODO: forward (softmax/log-softmax + NLL), backward (A - one_hot(Y))\n","    ...\n"],"metadata":{"id":"fjxeufrGs7HS"}}]}