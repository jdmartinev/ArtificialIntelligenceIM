{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj9xP5j599Hn"
   },
   "source": [
    "# Transferencia de Aprendizaje en el Conjunto de Datos Caltech101\n",
    "\n",
    "En este cuaderno, consideraremos un conjunto de datos más complejo que MNIST o CIFAR10. Las imágenes en Caltech101 son imágenes RGB (3 canales) con tamaño variable. Hay 101 clases diferentes. Intentaremos una práctica muy común en visión por computadora en la actualidad: transferencia de aprendizaje desde un modelo preentrenado en ImageNet.\n",
    "\n",
    "## Plan de Trabajo:\n",
    "- Modificar la red del ejercicio anterior (CIFAR-10) para trabajar con imágenes de 224x224.\n",
    "- Entrenar el modelo por un tiempo en Caltech101 y ver qué tan lejos podemos llegar.\n",
    "- Tomar un ResNet34 que fue preentrenado en ImageNet-1k y ajustarlo a Caltech101.\n",
    "  - Considerar tanto entrenar solo la cabeza (el clasificador lineal al final de la red) como toda la red.\n",
    "  - Deberíamos poder alcanzar un mejor rendimiento que nuestra red original en menos pasos de entrenamiento.\n",
    "- Opcional: experimentar con otros modelos preentrenados de `timm` (ver información [aquí](https://github.com/rwightman/pytorch-image-models))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2o5PEgM-CAv"
   },
   "source": [
    "## Preliminares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gu6ync4s9ToL"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from typing import List, Optional, Callable, Iterator\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "!pip install timm\n",
    "import timm\n",
    "\n",
    "def accuracy(target, pred):\n",
    "    return accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())\n",
    "\n",
    "def show_image(img, title=None):\n",
    "    img = img.detach().cpu()\n",
    "    img = img.permute((1, 2, 0)).numpy()\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std * img + mean   # unnormalize\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.gca().tick_params(axis=\"both\", which=\"both\", bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsGxVBpl-LtR"
   },
   "source": [
    "## Configuración de la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1724686235018,
     "user": {
      "displayName": "Juan David Martinez Vargas",
      "userId": "15315348669826032119"
     },
     "user_tz": 300
    },
    "id": "DOR0N6NV-XbI",
    "outputId": "d00f91eb-7828-4224-c6f2-39d87f05e295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "default_imagenet_normalization = transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.25, 1)),  # crop of random size and aspect ratio, resize to square\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    default_imagenet_normalization,\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # keep aspect ratio\n",
    "    transforms.CenterCrop(224),  # square crop\n",
    "    transforms.ToTensor(),\n",
    "    default_imagenet_normalization,\n",
    "])\n",
    "\n",
    "batch_size = 64  # both for training and testing\n",
    "\n",
    "# Load dataset (downloaded automatically if missing).\n",
    "dataset = torchvision.datasets.Caltech101(root='./data', download=True)\n",
    "\n",
    "\n",
    "def translate_label(y, keep_classes):\n",
    "    try:\n",
    "        return keep_classes.index(y)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "\n",
    "# Filter images such that no class has more than 100 examples.\n",
    "# Loop through dataset in random order, include each image (its index) only if there are\n",
    "# fewer than 100 images of the same class.\n",
    "# Here we also remove the classes \"Faces\" and \"Faces_easy\".\n",
    "skip_classes = [0, 1]   # \"Faces\" and \"Faces_easy\"\n",
    "keep_classes = [c for c in range(len(dataset.categories)) if c not in skip_classes]\n",
    "indices = list(range(len(dataset)))\n",
    "random.shuffle(indices)\n",
    "new_indices = []\n",
    "current_class_size = {class_number: 0 for class_number in np.unique(dataset.y)}\n",
    "for i in indices:\n",
    "    class_number = dataset.y[i]\n",
    "    if class_number not in skip_classes and current_class_size[class_number] < 100:\n",
    "        new_indices.append(i)\n",
    "        current_class_size[class_number] += 1\n",
    "indices = new_indices\n",
    "\n",
    "# Compute subset of labels given new indices selection\n",
    "labels = [translate_label(dataset.y[i], keep_classes) for i in indices]\n",
    "assert max(labels) == 98\n",
    "\n",
    "test_size = 640\n",
    "train_size = len(indices) - test_size\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices,\n",
    "    train_size=train_size,\n",
    "    test_size=test_size,\n",
    "    shuffle=True,\n",
    "    random_state=42,  # always get the same split\n",
    "    stratify=labels,\n",
    ")\n",
    "\n",
    "class DatasetWithTransform(Dataset):\n",
    "    def __init__(self, dataset, indices=None, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices if indices is not None else list(range(len(dataset)))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the actual dataset index\n",
    "        actual_idx = self.indices[idx]\n",
    "        x, y = self.dataset[actual_idx]\n",
    "\n",
    "        # Convert PIL image to RGB\n",
    "        x = x.convert('RGB')\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        # Translate the label\n",
    "        y = translate_label(y, keep_classes)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OavwV_WyKx5_"
   },
   "outputs": [],
   "source": [
    "train_set = DatasetWithTransform(dataset, train_idx, train_transform)\n",
    "test_set = DatasetWithTransform(dataset, test_idx, test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OAWxaej-e8B"
   },
   "source": [
    "### Un Vistazo Más Cercano al Conjunto de Datos\n",
    "\n",
    "Primero, trazamos el tamaño de cada clase y observamos que la distribución de clases no es uniforme.\n",
    "\n",
    "Luego, mostramos ejemplos aleatorios del conjunto de datos, anotados con la etiqueta de la clase y el índice.\n",
    "Ten en cuenta que las imágenes de entrenamiento incluyen aumentos estándar que se utilizan típicamente en modelos de visión (definidos anteriormente).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "11h5fzXrHEv_5kwARwtGKWOTVnu-XMRra"
    },
    "executionInfo": {
     "elapsed": 11556,
     "status": "ok",
     "timestamp": 1724686261680,
     "user": {
      "displayName": "Juan David Martinez Vargas",
      "userId": "15315348669826032119"
     },
     "user_tz": 300
    },
    "id": "RvSNIeX4-irO",
    "outputId": "a766994c-067e-4f69-c9d2-ee7a654f786d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_idxs, counts = np.unique(labels, return_counts=True)\n",
    "plt.figure(figsize=(20, 4.2))\n",
    "sns.barplot(x=[dataset.categories[keep_classes[label]] for label in label_idxs], y=counts, color=sns.color_palette('muted')[0])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of examples\")\n",
    "plt.title(\"Class distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def show_dataset_examples(dataloader):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    with sns.axes_style(\"white\"):\n",
    "      fig, axes = plt.subplots(4, 8, figsize=(16, 9.5))\n",
    "    axes = [ax for axes_ in axes for ax in axes_]   # flatten\n",
    "    for j, (img, label) in enumerate(zip(images[:32], labels[:32])):\n",
    "        plt.sca(axes[j])\n",
    "        show_image(img, title=f\"{dataset.categories[keep_classes[label.item()]]} ({label.item()})\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n\\nTrain images (including augmentations):\")\n",
    "show_dataset_examples(train_loader)\n",
    "print(\"\\n\\nTest images:\")\n",
    "show_dataset_examples(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyLUh4lV-x9n"
   },
   "source": [
    "## Definir una Red Neuronal\n",
    "\n",
    "**Asignación 1:** Crea una arquitectura de red neuronal para manejar imágenes de 224x224. Recomendamos reducir significativamente el tamaño de los tensores antes de aplanarlos, añadiendo capas convolucionales con `stride > 1` o capas de [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) (pero también puedes considerar [AvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1724680777429,
     "user": {
      "displayName": "Juan David Martinez Vargas",
      "userId": "15315348669826032119"
     },
     "user_tz": 300
    },
    "id": "H_GKJ66F-7YJ",
    "outputId": "dfe579ba-9bd0-4239-f0d4-9af2bc95246c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model()\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = ...   # Your code here!\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "model = Model(num_classes=len(np.unique(labels)))\n",
    "device = torch.device('cuda')  # use cuda or cpu\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FsfDC6b_Rnc"
   },
   "source": [
    "## Definir la Función de Pérdida y el Optimizador\n",
    "\n",
    "**Asignación:** Implementa el criterio y el optimizador, como en el cuaderno anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPTspIkq_XCA"
   },
   "outputs": [],
   "source": [
    "loss_fn = None  # Your code here!\n",
    "optimizer = None  # Your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TuB4ayd_YQT"
   },
   "source": [
    "## Entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwGXHNpA_a2_"
   },
   "outputs": [],
   "source": [
    "# Test the forward pass with dummy data\n",
    "out = model(torch.randn(2, 3, 224, 224).to(device))\n",
    "print(\"Output shape:\", out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGR_GWpo_fF5"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "validation_every_steps = 50\n",
    "\n",
    "step = 0\n",
    "model.train()\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_accuracies_batches = []\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Forward pass.\n",
    "        output = model(inputs)\n",
    "\n",
    "        # Compute loss.\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        # Clean up gradients from the model.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute gradients based on the loss from the current batch (backpropagation).\n",
    "        loss.backward()\n",
    "\n",
    "        # Take one optimizer step using the gradients computed in the previous step.\n",
    "        optimizer.step()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # Compute accuracy.\n",
    "        predictions = output.max(1)[1]\n",
    "        train_accuracies_batches.append(accuracy(targets, predictions))\n",
    "\n",
    "        if step % validation_every_steps == 0:\n",
    "\n",
    "            # Append average training accuracy to list.\n",
    "            train_accuracies.append(np.mean(train_accuracies_batches))\n",
    "\n",
    "            train_accuracies_batches = []\n",
    "\n",
    "            # Compute accuracies on validation set.\n",
    "            valid_accuracies_batches = []\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for inputs, targets in test_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    output = model(inputs)\n",
    "                    loss = loss_fn(output, targets)\n",
    "\n",
    "                    predictions = output.max(1)[1]\n",
    "\n",
    "                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
    "                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))\n",
    "\n",
    "                model.train()\n",
    "\n",
    "            # Append average validation accuracy to list.\n",
    "            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))\n",
    "\n",
    "            print(f\"Step {step:<5}   training accuracy: {train_accuracies[-1]}\")\n",
    "            print(f\"             test accuracy: {valid_accuracies[-1]}\")\n",
    "\n",
    "print(\"Finished training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJQ_DcWO_h2M"
   },
   "source": [
    "# Evaluar la red en el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DaEorgsW_mEE"
   },
   "outputs": [],
   "source": [
    "# Evaluate test set\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_accuracies = []\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        predictions = output.max(1)[1]\n",
    "\n",
    "        # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=True).\n",
    "        test_accuracies.append(accuracy(targets, predictions) * len(inputs))\n",
    "\n",
    "    test_accuracy = np.sum(test_accuracies) / len(test_set)\n",
    "    print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01ojnP3G_pzl"
   },
   "source": [
    "## Usando un Modelo Preentrenado\n",
    "\n",
    "Aquí cargaremos un ResNet34 que fue preentrenado en ImageNet. Luego, descartaremos el clasificador lineal al final de la red (la \"cabeza\" de la red) y lo reemplazaremos con uno nuevo que produzca el número deseado de logits para la clasificación. Para obtener una idea general de la estructura del modelo, lo imprimimos a continuación.\n",
    "\n",
    "El argumento `finetune_entire_model` en `initialize_model()` controla si se ajusta toda la red preentrenada. Cuando esto es `False`, solo se entrena la cabeza lineal y el resto del modelo se mantiene fijo. La idea es que las características extraídas por el modelo de ImageNet, hasta la capa de clasificación final, también son muy informativas en otros conjuntos de datos (ver, por ejemplo, [este artículo](https://arxiv.org/abs/1910.04867) sobre la transferibilidad de representaciones profundas en modelos de visión grandes).\n",
    "\n",
    "Comenzaremos aquí entrenando solo la cabeza lineal. Puedes experimentar con diferentes modelos y variaciones.\n",
    "\n",
    "A continuación, definimos el modelo y descartamos el que acabamos de entrenar. Después de eso, puedes volver a la sección \"Definir la Función de Pérdida y el Optimizador\" y volver a ejecutar el cuaderno desde allí, para entrenar y evaluar el nuevo modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OizUhxEc_-UN"
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name: str, *, num_classes: int, finetune_entire_model: bool = False):\n",
    "    \"\"\"Returns a pretrained model with a new last layer, and a dict with additional info.\n",
    "\n",
    "    The dict now contains the number of model parameters, computed as the number of\n",
    "    trainable parameters as soon as the model is loaded.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\n",
    "        f\"Loading model '{model_name}', with \"\n",
    "        f\"finetune_entire_model={finetune_entire_model}, changing the \"\n",
    "        f\"last layer to output {num_classes} logits.\"\n",
    "    )\n",
    "    model = timm.create_model(\n",
    "        model_name, pretrained=True, num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    num_model_parameters = 0\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad:\n",
    "            num_model_parameters += p.numel()\n",
    "\n",
    "    if not finetune_entire_model:\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Layer names are not consistent, so we have to consider a few cases. This might\n",
    "        # break for arbitrary models from timm (we have not checked all available models).\n",
    "        layer = None\n",
    "        if hasattr(model, \"classifier\"):\n",
    "            if isinstance(model.classifier, nn.Linear):\n",
    "                layer = model.classifier\n",
    "        elif hasattr(model, \"head\"):\n",
    "            if isinstance(model.head, nn.Linear):\n",
    "                layer = model.head\n",
    "            elif hasattr(model.head, \"fc\") and isinstance(model.head.fc, nn.Linear):\n",
    "                layer = model.head.fc\n",
    "            elif hasattr(model.head, \"l\") and isinstance(model.head.l, nn.Linear):\n",
    "                layer = model.head.l\n",
    "        elif hasattr(model, \"fc\"):\n",
    "            if isinstance(model.fc, nn.Linear):\n",
    "                layer = model.fc\n",
    "        if layer is None:\n",
    "            raise ValueError(f\"Couldn't automatically find last layer of model.\")\n",
    "\n",
    "        # Make the last layer trainable.\n",
    "        layer.weight.requires_grad_()\n",
    "        layer.bias.requires_grad_()\n",
    "\n",
    "    num_trainable_model_parameters = 0\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad:\n",
    "            num_trainable_model_parameters += p.numel()\n",
    "\n",
    "    return model, {\n",
    "        \"num_model_parameters\": num_model_parameters,\n",
    "        \"num_trainable_model_parameters\": num_trainable_model_parameters,\n",
    "    }\n",
    "\n",
    "model, data = initialize_model('resnet34d', num_classes=len(np.unique(labels)), finetune_entire_model=False)\n",
    "\n",
    "print(model)\n",
    "print(\"Number of model parameters:\", data[\"num_model_parameters\"])\n",
    "print(\"Number of trainable parameters:\", data[\"num_trainable_model_parameters\"])\n",
    "\n",
    "device = torch.device('cuda')  # use cuda or cpu\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1P4fvccOANv6"
   },
   "source": [
    "**Asignación:**\n",
    "\n",
    "1. Entrena el clasificador lineal sobre la red preentrenada y observa qué tan rápido puedes obtener buenos resultados, en comparación con entrenar una red más pequeña desde cero como hicimos anteriormente.\n",
    "\n",
    "2. Vuelve atrás y cambia el argumento para ajustar toda la red (`finetune_entire_model`), tal vez ajusta la tasa de aprendizaje, y observa si puedes obtener un mejor rendimiento que antes y si encuentras algún problema.\n",
    "\n",
    "3. Opcional: experimenta con `timm`: prueba modelos más pequeños o más grandes, incluyendo modelos de última generación, por ejemplo, basados en transformadores de visión (ViT) o MLP-Mixers.\n",
    "\n",
    "4. Describe brevemente lo que hiciste y cualquier experimento que realizaste, así como los resultados que obtuviste.\n",
    "¿Algo te sorprendió durante el ejercicio?\n",
    "\n",
    "5. Escribe las lecciones o ideas clave que obtuviste durante este ejercicio.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPiokCVWUuxKP4xtOZ6YcYJ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
